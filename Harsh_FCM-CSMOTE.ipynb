{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/harshj3915/Intuitionistic-FCM-Smote/blob/Harsh/Harsh_FCM-CSMOTE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {},
      "outputs": [],
      "source": [
        "# %pip install numpy\n",
        "# %pip install -q numpy scikit-learn imbalanced-learn\n",
        "# %pip install ucimlrepo matplotlib\n",
        "# %pip install -U imbalanced-learn fcmeans\n",
        "# %pip install -U scikit-learn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'uci_id': 53, 'name': 'Iris', 'repository_url': 'https://archive.ics.uci.edu/dataset/53/iris', 'data_url': 'https://archive.ics.uci.edu/static/public/53/data.csv', 'abstract': 'A small classic dataset from Fisher, 1936. One of the earliest known datasets used for evaluating classification methods.\\n', 'area': 'Biology', 'tasks': ['Classification'], 'characteristics': ['Tabular'], 'num_instances': 150, 'num_features': 4, 'feature_types': ['Real'], 'demographics': [], 'target_col': ['class'], 'index_col': None, 'has_missing_values': 'no', 'missing_values_symbol': None, 'year_of_dataset_creation': 1936, 'last_updated': 'Tue Sep 12 2023', 'dataset_doi': '10.24432/C56C76', 'creators': ['R. A. Fisher'], 'intro_paper': {'ID': 191, 'type': 'NATIVE', 'title': 'The Iris data set: In search of the source of virginica', 'authors': 'A. Unwin, K. Kleinman', 'venue': 'Significance, 2021', 'year': 2021, 'journal': 'Significance, 2021', 'DOI': '1740-9713.01589', 'URL': 'https://www.semanticscholar.org/paper/4599862ea877863669a6a8e63a3c707a787d5d7e', 'sha': None, 'corpus': None, 'arxiv': None, 'mag': None, 'acl': None, 'pmid': None, 'pmcid': None}, 'additional_info': {'summary': 'This is one of the earliest datasets used in the literature on classification methods and widely used in statistics and machine learning.  The data set contains 3 classes of 50 instances each, where each class refers to a type of iris plant.  One class is linearly separable from the other 2; the latter are not linearly separable from each other.\\n\\nPredicted attribute: class of iris plant.\\n\\nThis is an exceedingly simple domain.\\n\\nThis data differs from the data presented in Fishers article (identified by Steve Chadwick,  spchadwick@espeedaz.net ).  The 35th sample should be: 4.9,3.1,1.5,0.2,\"Iris-setosa\" where the error is in the fourth feature. The 38th sample: 4.9,3.6,1.4,0.1,\"Iris-setosa\" where the errors are in the second and third features.  ', 'purpose': 'N/A', 'funded_by': None, 'instances_represent': 'Each instance is a plant', 'recommended_data_splits': None, 'sensitive_data': None, 'preprocessing_description': None, 'variable_info': None, 'citation': None}}\n",
            "           name     role         type demographic  \\\n",
            "0  sepal length  Feature   Continuous        None   \n",
            "1   sepal width  Feature   Continuous        None   \n",
            "2  petal length  Feature   Continuous        None   \n",
            "3   petal width  Feature   Continuous        None   \n",
            "4         class   Target  Categorical        None   \n",
            "\n",
            "                                         description units missing_values  \n",
            "0                                               None    cm             no  \n",
            "1                                               None    cm             no  \n",
            "2                                               None    cm             no  \n",
            "3                                               None    cm             no  \n",
            "4  class of iris plant: Iris Setosa, Iris Versico...  None             no  \n"
          ]
        }
      ],
      "source": [
        "from ucimlrepo import fetch_ucirepo \n",
        "  \n",
        "# fetch dataset \n",
        "iris = fetch_ucirepo(id=109) \n",
        "  \n",
        "# data (as pandas dataframes) \n",
        "X = iris.data.features \n",
        "y = iris.data.targets \n",
        "  \n",
        "# metadata \n",
        "print(iris.metadata) \n",
        "  \n",
        "# variable information \n",
        "print(iris.variables) \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.cluster import DBSCAN\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def extract_and_visualize_k_clusters_with_dbscan(X, k):\n",
        "    \"\"\"\n",
        "    Extract and visualize the first k clusters from the data using the DBSCAN algorithm.\n",
        "    \n",
        "    Args:\n",
        "    - X : Feature matrix (dataset)\n",
        "    - k : Number of clusters to extract\n",
        "    \n",
        "    Returns:\n",
        "    - k_clusters : List of the first k clusters\n",
        "    \"\"\"\n",
        "    # Apply DBSCAN to find clusters\n",
        "    dbscan = DBSCAN(eps=0.9, min_samples=10)\n",
        "    dbscan.fit(X)\n",
        "    \n",
        "    # Get the cluster labels assigned by DBSCAN\n",
        "    cluster_labels = dbscan.labels_\n",
        "    \n",
        "    # Identify the unique cluster labels (ignoring noise, labeled as -1)\n",
        "    unique_labels = np.unique(cluster_labels)\n",
        "    \n",
        "    # Initialize a list to store the first k clusters\n",
        "    k_clusters = []\n",
        "    \n",
        "    # Loop over unique labels and extract the first k clusters (excluding noise)\n",
        "    for label in unique_labels:\n",
        "        if label != -1 and len(k_clusters) < k:  # Ignore noise (-1) and stop when we get k clusters\n",
        "            cluster = X[cluster_labels == label]\n",
        "            k_clusters.append(cluster)\n",
        "\n",
        "    # Visualization of clusters using the first two features for 2D plotting\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    \n",
        "    # Loop over each cluster and plot\n",
        "    for label in unique_labels:\n",
        "        if label == -1:\n",
        "            # Plot noise points in black\n",
        "            plt.scatter(X[cluster_labels == label][:, 0], X[cluster_labels == label][:, 1], \n",
        "                        c='k', marker='x', label='Noise')\n",
        "        else:\n",
        "            if len(k_clusters) < k:  # Only plot up to k clusters\n",
        "                # Generate a color for the cluster\n",
        "                color = plt.cm.rainbow(float(label) / len(unique_labels))\n",
        "                plt.scatter(X[cluster_labels == label][:, 0], X[cluster_labels == label][:, 1], \n",
        "                            c=[color], label=f'Cluster {label}')\n",
        "    \n",
        "    # Add labels and title to the plot\n",
        "    plt.title(f'DBSCAN Clustering with First {k} Clusters')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "    \n",
        "    return k_clusters\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[1.423e+01 1.710e+00 2.430e+00 ... 1.040e+00 3.920e+00 1.065e+03]\n",
            " [1.320e+01 1.780e+00 2.140e+00 ... 1.050e+00 3.400e+00 1.050e+03]\n",
            " [1.316e+01 2.360e+00 2.670e+00 ... 1.030e+00 3.170e+00 1.185e+03]\n",
            " ...\n",
            " [1.327e+01 4.280e+00 2.260e+00 ... 5.900e-01 1.560e+00 8.350e+02]\n",
            " [1.317e+01 2.590e+00 2.370e+00 ... 6.000e-01 1.620e+00 8.400e+02]\n",
            " [1.413e+01 4.100e+00 2.740e+00 ... 6.100e-01 1.600e+00 5.600e+02]]\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[]\n"
          ]
        }
      ],
      "source": [
        "from ucimlrepo import fetch_ucirepo \n",
        "  \n",
        "# fetch dataset \n",
        "iris = fetch_ucirepo(id=109) \n",
        "  \n",
        "# data (as pandas dataframes) \n",
        "X = iris.data.features.values\n",
        "\n",
        "print(X)\n",
        "\n",
        "  \n",
        "print(extract_and_visualize_k_clusters_with_dbscan(X, 5))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics.pairwise import euclidean_distances\n",
        "from fcmeans import FCM\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "import copy\n",
        "import warnings\n",
        "import math\n",
        "import copy\n",
        "import numpy as np\n",
        "from sklearn.mixture import GaussianMixture\n",
        "from sklearn.utils import check_random_state\n",
        "from sklearn.metrics.pairwise import euclidean_distances\n",
        "from imblearn.over_sampling.base import BaseOverSampler\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "from imblearn.exceptions import raise_isinstance_error\n",
        "from imblearn.utils import check_neighbors_object\n",
        "from imblearn.utils.deprecation import deprecate_parameter\n",
        "class FCMCENTERSMOTE(BaseOverSampler):\n",
        "    def __init__(self, sampling_strategy='auto', random_state=None, kmeans_args=None, smote_args=None,\n",
        "                 imbalance_ratio_threshold=1.0, density_power=None, use_minibatch_kmeans=True, n_jobs=1, **kwargs):\n",
        "        super(FCMCENTERSMOTE, self).__init__(sampling_strategy=sampling_strategy, **kwargs)\n",
        "        if kmeans_args is None:\n",
        "            kmeans_args = {}\n",
        "        if smote_args is None:\n",
        "            smote_args = {}\n",
        "        self.imbalance_ratio_threshold = imbalance_ratio_threshold\n",
        "        self.kmeans_args = copy.deepcopy(kmeans_args)\n",
        "        self.smote_args = copy.deepcopy(smote_args)\n",
        "        self.random_state = random_state\n",
        "        self.n_jobs = n_jobs\n",
        "        self.use_minibatch_kmeans = use_minibatch_kmeans\n",
        "        self.density_power = density_power\n",
        "\n",
        "    def _cluster(self, X):\n",
        "        fcm = FCM(**self.kmeans_args)\n",
        "        fcm.fit(X)\n",
        "        fcm_labels = fcm.predict(X)\n",
        "        cluster_assignment = np.asarray(fcm_labels)\n",
        "        print(\"cluster_assignment\",cluster_assignment)\n",
        "        return cluster_assignment\n",
        "\n",
        "    def _filter_clusters(self, X, y, cluster_assignment, minority_class_label):\n",
        "      largest_cluster_label = np.max(np.unique(cluster_assignment))\n",
        "      sparsity_factors = np.zeros((largest_cluster_label + 1,), dtype=np.float64)\n",
        "      minority_mask = (y == minority_class_label)\n",
        "      imbalance_ratio_threshold = self.imbalance_ratio_threshold\n",
        "      \n",
        "\n",
        "      if isinstance(imbalance_ratio_threshold, dict):\n",
        "          imbalance_ratio_threshold = imbalance_ratio_threshold.get(minority_class_label, 1.0)\n",
        "\n",
        "      for i in np.unique(cluster_assignment):\n",
        "          cluster = X[cluster_assignment == i]\n",
        "          mask = minority_mask[cluster_assignment == i]\n",
        "          minority_count = np.sum(mask)\n",
        "          majority_count = np.sum(~mask)\n",
        "          imbalance_ratio = (majority_count + 1) / (minority_count + 1)\n",
        "\n",
        "          if (imbalance_ratio < imbalance_ratio_threshold) and (minority_count > 1):\n",
        "              distances = euclidean_distances(cluster[mask])\n",
        "              non_diagonal_distances = distances[~np.eye(distances.shape[0], dtype=bool)]\n",
        "              average_minority_distance = np.mean(non_diagonal_distances) if non_diagonal_distances.size > 0 else 0.0\n",
        "\n",
        "              if average_minority_distance == 0:\n",
        "                  average_minority_distance = 1e-1\n",
        "\n",
        "              density_factor = minority_count / (average_minority_distance ** self.density_power)\n",
        "              sparsity_factors[i] = 1 / density_factor\n",
        "\n",
        "      sparsity_sum = np.sum(sparsity_factors)\n",
        "      if sparsity_sum == 0:\n",
        "          sparsity_sum = 1\n",
        "\n",
        "      sampling_weights = sparsity_factors / sparsity_sum if sparsity_sum != 0 else np.full(sparsity_factors.shape, 1.0)\n",
        "\n",
        "      return sampling_weights\n",
        "    @staticmethod\n",
        "    def smote_oversample_with_point_value(X, y, point_index, sampling_ratio=1.0,smote_args= None,k=5):\n",
        "      if smote_args is not None and 'k_neighbors' in smote_args:\n",
        "            k = smote_args['k_neighbors']\n",
        "      minority_class = np.unique(y)[np.argmin(np.bincount(y))]\n",
        "      minority_indices = np.where(y == minority_class)[0]\n",
        "      print(point_index)\n",
        "      print(\"hehe \", isinstance(point_index, int) and point_index < len(y) and y[point_index] == minority_class)\n",
        "      \n",
        "\n",
        "\n",
        "      if isinstance(point_index, int) and point_index < len(y) and y[point_index] == minority_class:\n",
        "        num_minority_samples = len(minority_indices)\n",
        "        num_majority_samples = int(sampling_ratio * len(y)) - num_minority_samples\n",
        "\n",
        "        knn = NearestNeighbors(n_neighbors=k + 1)\n",
        "        knn.fit(X[minority_indices])\n",
        "        nn_indices = knn.kneighbors([X[point_index]], return_distance=False)[0][1:]\n",
        "\n",
        "        synthetic_samples = []\n",
        "        for i in range(num_minority_samples):\n",
        "            nn_index = np.random.choice(nn_indices)\n",
        "            diff = X[nn_index] - X[point_index]\n",
        "            synthetic_sample = X[point_index] + np.random.rand() * diff\n",
        "            synthetic_samples.append(synthetic_sample)\n",
        "        synthetic_samples = np.array(synthetic_samples)\n",
        "\n",
        "        X_resampled = np.vstack((X, synthetic_samples))\n",
        "        y_resampled = np.hstack((y, np.full(len(synthetic_samples), minority_class)))\n",
        "\n",
        "        shuffle_indices = np.random.permutation(len(X_resampled))\n",
        "        X_resampled = X_resampled[shuffle_indices]\n",
        "        y_resampled = y_resampled[shuffle_indices]\n",
        "\n",
        "        return X_resampled, y_resampled\n",
        "      else:\n",
        "        return X, y\n",
        "\n",
        "    def _fit_resample(self, X, y):\n",
        "        \"\"\"Resample the dataset.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        X : ndarray, shape (n_samples, n_features)\n",
        "            Matrix containing the data which have to be sampled.\n",
        "\n",
        "        y : ndarray, shape (n_samples, )\n",
        "            Corresponding label for each sample in X.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        X_resampled : ndarray, shape (n_samples_new, n_features)\n",
        "            The array containing the resampled data.\n",
        "\n",
        "        y_resampled : ndarray, shape (n_samples_new)\n",
        "            The corresponding labels of ``X_resampled``\n",
        "\n",
        "        \"\"\"\n",
        "        self._set_subalgorithm_params()\n",
        "\n",
        "        if self.density_power is None:\n",
        "            self.density_power = X.shape[1]\n",
        "\n",
        "        resampled = [ (X.copy(), y.copy()) ]\n",
        "        sampling_ratio = {k: v for k, v in self.sampling_strategy_.items()}\n",
        "        # sampling_strategy_ does not contain classes where n_samples 0\n",
        "        for class_label in np.unique(y):\n",
        "            if class_label not in sampling_ratio:\n",
        "                sampling_ratio[class_label] = 0\n",
        "        print(\"sampling_ratio\",sampling_ratio)\n",
        "        for minority_class_label, n_samples in sampling_ratio.items():\n",
        "            print(\"minority_class_label\",minority_class_label)\n",
        "            if n_samples == 0:\n",
        "                continue\n",
        "\n",
        "            cluster_assignment = self._cluster(X)\n",
        "            sampling_weights = self._filter_clusters(X, y, cluster_assignment, minority_class_label)\n",
        "            print('Sampling Weights : ',sampling_weights)\n",
        "            smote_args = self.smote_args.copy()\n",
        "            if np.count_nonzero(sampling_weights) > 0:\n",
        "                # perform k-means smote\n",
        "                for i in np.unique(cluster_assignment):\n",
        "                    \n",
        "                    cluster_X = X[cluster_assignment == i]\n",
        "                    cluster_y = y[cluster_assignment == i]\n",
        "                    if sampling_weights[i] > 0:\n",
        "                        # determine ratio for oversampling the current cluster\n",
        "                        target_ratio = {label: np.count_nonzero(cluster_y == label) for label in sampling_ratio}\n",
        "                        cluster_minority_count = np.count_nonzero(cluster_y == minority_class_label)\n",
        "                        generate_count = int(round(n_samples * sampling_weights[i]))\n",
        "                        target_ratio[minority_class_label] = generate_count + cluster_minority_count\n",
        "\n",
        "                        # make sure that cluster_y has more than 1 class, adding a random point otherwise\n",
        "                        remove_index = -1\n",
        "                        if np.unique(cluster_y).size < 2:\n",
        "                            remove_index = cluster_y.size\n",
        "                            cluster_X = np.append(cluster_X, np.zeros((1,cluster_X.shape[1])), axis=0)\n",
        "                            majority_class_label = next( key for key in sampling_ratio.keys() if key != minority_class_label )\n",
        "                            target_ratio[majority_class_label] = 1 + target_ratio[majority_class_label]\n",
        "                            cluster_y = np.append(cluster_y, np.asarray(majority_class_label).reshape((1,)), axis=0)\n",
        "                        \n",
        "                        # clear target ratio of labels not present in cluster\n",
        "                        for label in list(target_ratio.keys()):\n",
        "                            if label not in cluster_y:\n",
        "                                del target_ratio[label]\n",
        "                        \n",
        "                        # modify copy of the user defined smote_args to reflect computed parameters\n",
        "                        smote_args['sampling_strategy'] = target_ratio\n",
        "                        \n",
        "                        \n",
        "                        smote_args = self._validate_smote_args(smote_args, cluster_minority_count)\n",
        "                        # Get the center of the cluster to use as the point for SMOTE oversampling\n",
        "                        cluster_center = np.mean(cluster_X, axis=0)\n",
        "                        k_value = smote_args['k_neighbors']\n",
        "                        print(\"cluster_center\",cluster_center)\n",
        "                        print('k_value',k_value)\n",
        "                        print(\"i\",i)\n",
        "                        X_resampled_cluster, y_resampled_cluster = self.smote_oversample_with_point_value(\n",
        "                            X, y, cluster_center, sampling_ratio=n_samples / X.shape[0],\n",
        "                            k=k_value)\n",
        "                        print(\"After \",X_resampled_cluster)\n",
        "                        \n",
        "                        # if k_neighbors is 0, perform random oversampling instead of smote\n",
        "                        if 'k_neighbors' in smote_args and smote_args['k_neighbors'] == 0:\n",
        "                                oversampler_args = {}\n",
        "                                if 'random_state' in smote_args:\n",
        "                                    oversampler_args['random_state'] = smote_args['random_state']\n",
        "                                oversampler = RandomOverSampler(**oversampler_args)\n",
        "                        print(\"line 1\")\n",
        "                        # finally, apply smote to cluster\n",
        "                        with warnings.catch_warnings():\n",
        "                            # ignore warnings about minority class getting bigger than majority class\n",
        "                            # since this would only be true within this cluster\n",
        "                            warnings.filterwarnings(action='ignore', category=UserWarning, message=r'After over-sampling, the number of samples \\(.*\\) in class .* will be larger than the number of samples in the majority class \\(class #.* \\-\\> .*\\)')\n",
        "                            cluster_resampled_X, cluster_resampled_y = self.smote_oversample_with_point_value(\n",
        "                            X, y, cluster_center, sampling_ratio=n_samples / X.shape[0],\n",
        "                            k=smote_args['k_neighbors'])\n",
        "                        print(\"line 2\")\n",
        "                        if remove_index > -1:\n",
        "                            # since SMOTE's results are ordered the same way as the data passed into it,\n",
        "                            # the temporarily added point is at the same index position as it was added.\n",
        "                            for l in [cluster_resampled_X, cluster_resampled_y, cluster_X, cluster_y]:\n",
        "                                np.delete(l, remove_index, 0)\n",
        "\n",
        "                        # add new generated samples to resampled\n",
        "                        print(resampled[-2:])\n",
        "                        resampled.append( (\n",
        "                            cluster_resampled_X[cluster_y.size:,:],\n",
        "                            cluster_resampled_y[cluster_y.size:]))\n",
        "                        print(resampled[-2:])\n",
        "                        \n",
        "            else:\n",
        "                # all weights are zero -> perform regular smote\n",
        "                warnings.warn('No minority clusters found for class {}. Performing regular SMOTE. Try changing the number of clusters.'.format(minority_class_label))\n",
        "                target_ratio = {label: np.count_nonzero(y == label) for label in sampling_ratio}\n",
        "                target_ratio[minority_class_label] = sampling_ratio[minority_class_label]\n",
        "                minority_count = np.count_nonzero(y == minority_class_label)\n",
        "                smote_args = self._validate_smote_args(smote_args, minority_count)\n",
        "                # Get the center of the cluster to use as the point for SMOTE oversampling\n",
        "                cluster_center = np.mean(cluster_X, axis=0)\n",
        "                X_resampled_cluster, y_resampled_cluster = self.smote_oversample_with_point_value(\n",
        "                    X, y, cluster_center, sampling_ratio=n_samples / X.shape[0],\n",
        "                            k=smote_args['k_neighbors'])\n",
        "\n",
        "        print(\"resampled\",resampled)\n",
        "        resampled = list(zip(*resampled))\n",
        "        if(len(resampled) > 0):\n",
        "            X_resampled = np.concatenate(resampled[0], axis=0)\n",
        "            y_resampled = np.concatenate(resampled[1], axis=0)\n",
        "        return X_resampled, y_resampled\n",
        "\n",
        "    def _validate_smote_args(self, smote_args, minority_count):\n",
        "      max_k_neighbors = minority_count - 1\n",
        "      if 'k' in smote_args and smote_args['k'] > max_k_neighbors:\n",
        "          smote_args['k'] = max_k_neighbors\n",
        "      return smote_args\n",
        "\n",
        "    def _set_subalgorithm_params(self):\n",
        "      if self.random_state is not None:\n",
        "          if 'random_state' not in self.smote_args:\n",
        "              self.smote_args['random_state'] = self.random_state\n",
        "          if 'random_state' not in self.kmeans_args:\n",
        "              self.kmeans_args['random_state'] = self.random_state\n",
        "\n",
        "      if self.n_jobs is not None:\n",
        "          if 'n_jobs' not in self.smote_args:\n",
        "              self.smote_args['n_jobs'] = self.n_jobs\n",
        "          if 'n_jobs' not in self.kmeans_args:\n",
        "              if not self.use_minibatch_kmeans:\n",
        "                  self.kmeans_args['n_jobs'] = self.n_jobs\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of occurrences of -1 in the 'Class' column: 0\n",
            "Distinct classes: [0 1]\n",
            "{'uci_id': 53, 'name': 'Iris', 'repository_url': 'https://archive.ics.uci.edu/dataset/53/iris', 'data_url': 'https://archive.ics.uci.edu/static/public/53/data.csv', 'abstract': 'A small classic dataset from Fisher, 1936. One of the earliest known datasets used for evaluating classification methods.\\n', 'area': 'Biology', 'tasks': ['Classification'], 'characteristics': ['Tabular'], 'num_instances': 150, 'num_features': 4, 'feature_types': ['Real'], 'demographics': [], 'target_col': ['class'], 'index_col': None, 'has_missing_values': 'no', 'missing_values_symbol': None, 'year_of_dataset_creation': 1936, 'last_updated': 'Tue Sep 12 2023', 'dataset_doi': '10.24432/C56C76', 'creators': ['R. A. Fisher'], 'intro_paper': {'ID': 191, 'type': 'NATIVE', 'title': 'The Iris data set: In search of the source of virginica', 'authors': 'A. Unwin, K. Kleinman', 'venue': 'Significance, 2021', 'year': 2021, 'journal': 'Significance, 2021', 'DOI': '1740-9713.01589', 'URL': 'https://www.semanticscholar.org/paper/4599862ea877863669a6a8e63a3c707a787d5d7e', 'sha': None, 'corpus': None, 'arxiv': None, 'mag': None, 'acl': None, 'pmid': None, 'pmcid': None}, 'additional_info': {'summary': 'This is one of the earliest datasets used in the literature on classification methods and widely used in statistics and machine learning.  The data set contains 3 classes of 50 instances each, where each class refers to a type of iris plant.  One class is linearly separable from the other 2; the latter are not linearly separable from each other.\\n\\nPredicted attribute: class of iris plant.\\n\\nThis is an exceedingly simple domain.\\n\\nThis data differs from the data presented in Fishers article (identified by Steve Chadwick,  spchadwick@espeedaz.net ).  The 35th sample should be: 4.9,3.1,1.5,0.2,\"Iris-setosa\" where the error is in the fourth feature. The 38th sample: 4.9,3.6,1.4,0.1,\"Iris-setosa\" where the errors are in the second and third features.  ', 'purpose': 'N/A', 'funded_by': None, 'instances_represent': 'Each instance is a plant', 'recommended_data_splits': None, 'sensitive_data': None, 'preprocessing_description': None, 'variable_info': None, 'citation': None}}\n",
            "           name     role         type demographic  \\\n",
            "0  sepal length  Feature   Continuous        None   \n",
            "1   sepal width  Feature   Continuous        None   \n",
            "2  petal length  Feature   Continuous        None   \n",
            "3   petal width  Feature   Continuous        None   \n",
            "4         class   Target  Categorical        None   \n",
            "\n",
            "                                         description units missing_values  \n",
            "0                                               None    cm             no  \n",
            "1                                               None    cm             no  \n",
            "2                                               None    cm             no  \n",
            "3                                               None    cm             no  \n",
            "4  class of iris plant: Iris Setosa, Iris Versico...  None             no  \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\91843\\AppData\\Local\\Temp\\ipykernel_23128\\2426638330.py:18: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  df['Class'] = df['Class'].replace('Iris-virginica', 1)   # Set class 2 to 1\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from ucimlrepo import fetch_ucirepo \n",
        "\n",
        "# Fetch the Iris dataset\n",
        "iris = fetch_ucirepo(id=53)\n",
        "\n",
        "\n",
        "# Data (as pandas DataFrames)\n",
        "df = pd.DataFrame(iris.data.features)\n",
        "\n",
        "df['Class'] = iris.data.targets\n",
        "\n",
        "\n",
        "# Replace target class labels (if needed)\n",
        "# Assuming you want to convert target classes to -1 and 1, you can customize this based on your requirements\n",
        "df['Class'] = df['Class'].replace('Iris-setosa', 0)  # Set class 0 to -1\n",
        "df['Class'] = df['Class'].replace('Iris-versicolor', 1)   # Keep class 1 as 1\n",
        "df['Class'] = df['Class'].replace('Iris-virginica', 1)   # Set class 2 to 1\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Features and target arrays\n",
        "X = df.iloc[:, :-1].to_numpy()  # All columns except the last one\n",
        "y = df['Class'].to_numpy()       # The last column as target\n",
        "\n",
        "\n",
        "# Count occurrences of -1 in the target variable\n",
        "count_of_minus_one = (y == -1).sum()\n",
        "print(\"Number of occurrences of -1 in the 'Class' column:\", count_of_minus_one)\n",
        "\n",
        "# Save the DataFrame to a CSV file\n",
        "df.to_csv('iris_dataset.csv', index=False)\n",
        "\n",
        "# Get unique classes\n",
        "unique_classes = df['Class'].unique()\n",
        "print(\"Distinct classes:\", unique_classes)\n",
        "\n",
        "# Display metadata and variable information\n",
        "print(iris.metadata)\n",
        "print(iris.variables)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Class 0 has 50 instances\n",
            "Class 1 has 100 instances\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "class_counts = dict(zip(*np.unique(y, return_counts=True)))\n",
        "\n",
        "for label, count in class_counts.items():\n",
        "    print('Class {} has {} instances'.format(label, count))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of clusters found by DBSCAN: 3\n"
          ]
        }
      ],
      "source": [
        "from sklearn.cluster import DBSCAN\n",
        "import numpy as np\n",
        "\n",
        "# Assuming 'X' contains your data\n",
        "\n",
        "# Instantiating DBSCAN\n",
        "dbscan = DBSCAN(eps=0.2, min_samples=4)  # You may need to adjust eps and min_samples\n",
        "\n",
        "# Fitting DBSCAN to your data\n",
        "clusters = dbscan.fit_predict(X)\n",
        "\n",
        "# Getting unique cluster labels (excluding noise, labeled as -1)\n",
        "unique_labels = np.unique(clusters)\n",
        "num_clusters = len(unique_labels[unique_labels != 0])\n",
        "\n",
        "print(f\"Number of clusters found by DBSCAN: {num_clusters}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{0: 50, 1: 100}\n",
            "Class 0 has 50 instances\n",
            "Class 1 has 100 instances\n",
            "sampling_ratio {0: 50, 1: 0}\n",
            "minority_class_label 0\n",
            "cluster_assignment [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 2 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 2 2 2 2 1 2 2 2 2\n",
            " 2 2 1 2 2 2 2 2 1 2 1 2 1 2 2 1 1 2 2 2 2 2 1 2 2 2 2 1 2 2 2 1 2 2 2 1 2\n",
            " 2 1]\n",
            "Sampling Weights :  [1. 0. 0.]\n",
            "cluster_center [4.90784314 3.35098039 1.43529412 0.23921569]\n",
            "k_value 2\n",
            "i 0\n",
            "[4.90784314 3.35098039 1.43529412 0.23921569]\n",
            "hehe  False\n",
            "After  [[5.1 3.5 1.4 0.2]\n",
            " [4.9 3.  1.4 0.2]\n",
            " [4.7 3.2 1.3 0.2]\n",
            " [4.6 3.1 1.5 0.2]\n",
            " [5.  3.6 1.4 0.2]\n",
            " [5.4 3.9 1.7 0.4]\n",
            " [4.6 3.4 1.4 0.3]\n",
            " [5.  3.4 1.5 0.2]\n",
            " [4.4 2.9 1.4 0.2]\n",
            " [4.9 3.1 1.5 0.1]\n",
            " [5.4 3.7 1.5 0.2]\n",
            " [4.8 3.4 1.6 0.2]\n",
            " [4.8 3.  1.4 0.1]\n",
            " [4.3 3.  1.1 0.1]\n",
            " [5.8 4.  1.2 0.2]\n",
            " [5.7 4.4 1.5 0.4]\n",
            " [5.4 3.9 1.3 0.4]\n",
            " [5.1 3.5 1.4 0.3]\n",
            " [5.7 3.8 1.7 0.3]\n",
            " [5.1 3.8 1.5 0.3]\n",
            " [5.4 3.4 1.7 0.2]\n",
            " [5.1 3.7 1.5 0.4]\n",
            " [4.6 3.6 1.  0.2]\n",
            " [5.1 3.3 1.7 0.5]\n",
            " [4.8 3.4 1.9 0.2]\n",
            " [5.  3.  1.6 0.2]\n",
            " [5.  3.4 1.6 0.4]\n",
            " [5.2 3.5 1.5 0.2]\n",
            " [5.2 3.4 1.4 0.2]\n",
            " [4.7 3.2 1.6 0.2]\n",
            " [4.8 3.1 1.6 0.2]\n",
            " [5.4 3.4 1.5 0.4]\n",
            " [5.2 4.1 1.5 0.1]\n",
            " [5.5 4.2 1.4 0.2]\n",
            " [4.9 3.1 1.5 0.1]\n",
            " [5.  3.2 1.2 0.2]\n",
            " [5.5 3.5 1.3 0.2]\n",
            " [4.9 3.1 1.5 0.1]\n",
            " [4.4 3.  1.3 0.2]\n",
            " [5.1 3.4 1.5 0.2]\n",
            " [5.  3.5 1.3 0.3]\n",
            " [4.5 2.3 1.3 0.3]\n",
            " [4.4 3.2 1.3 0.2]\n",
            " [5.  3.5 1.6 0.6]\n",
            " [5.1 3.8 1.9 0.4]\n",
            " [4.8 3.  1.4 0.3]\n",
            " [5.1 3.8 1.6 0.2]\n",
            " [4.6 3.2 1.4 0.2]\n",
            " [5.3 3.7 1.5 0.2]\n",
            " [5.  3.3 1.4 0.2]\n",
            " [7.  3.2 4.7 1.4]\n",
            " [6.4 3.2 4.5 1.5]\n",
            " [6.9 3.1 4.9 1.5]\n",
            " [5.5 2.3 4.  1.3]\n",
            " [6.5 2.8 4.6 1.5]\n",
            " [5.7 2.8 4.5 1.3]\n",
            " [6.3 3.3 4.7 1.6]\n",
            " [4.9 2.4 3.3 1. ]\n",
            " [6.6 2.9 4.6 1.3]\n",
            " [5.2 2.7 3.9 1.4]\n",
            " [5.  2.  3.5 1. ]\n",
            " [5.9 3.  4.2 1.5]\n",
            " [6.  2.2 4.  1. ]\n",
            " [6.1 2.9 4.7 1.4]\n",
            " [5.6 2.9 3.6 1.3]\n",
            " [6.7 3.1 4.4 1.4]\n",
            " [5.6 3.  4.5 1.5]\n",
            " [5.8 2.7 4.1 1. ]\n",
            " [6.2 2.2 4.5 1.5]\n",
            " [5.6 2.5 3.9 1.1]\n",
            " [5.9 3.2 4.8 1.8]\n",
            " [6.1 2.8 4.  1.3]\n",
            " [6.3 2.5 4.9 1.5]\n",
            " [6.1 2.8 4.7 1.2]\n",
            " [6.4 2.9 4.3 1.3]\n",
            " [6.6 3.  4.4 1.4]\n",
            " [6.8 2.8 4.8 1.4]\n",
            " [6.7 3.  5.  1.7]\n",
            " [6.  2.9 4.5 1.5]\n",
            " [5.7 2.6 3.5 1. ]\n",
            " [5.5 2.4 3.8 1.1]\n",
            " [5.5 2.4 3.7 1. ]\n",
            " [5.8 2.7 3.9 1.2]\n",
            " [6.  2.7 5.1 1.6]\n",
            " [5.4 3.  4.5 1.5]\n",
            " [6.  3.4 4.5 1.6]\n",
            " [6.7 3.1 4.7 1.5]\n",
            " [6.3 2.3 4.4 1.3]\n",
            " [5.6 3.  4.1 1.3]\n",
            " [5.5 2.5 4.  1.3]\n",
            " [5.5 2.6 4.4 1.2]\n",
            " [6.1 3.  4.6 1.4]\n",
            " [5.8 2.6 4.  1.2]\n",
            " [5.  2.3 3.3 1. ]\n",
            " [5.6 2.7 4.2 1.3]\n",
            " [5.7 3.  4.2 1.2]\n",
            " [5.7 2.9 4.2 1.3]\n",
            " [6.2 2.9 4.3 1.3]\n",
            " [5.1 2.5 3.  1.1]\n",
            " [5.7 2.8 4.1 1.3]\n",
            " [6.3 3.3 6.  2.5]\n",
            " [5.8 2.7 5.1 1.9]\n",
            " [7.1 3.  5.9 2.1]\n",
            " [6.3 2.9 5.6 1.8]\n",
            " [6.5 3.  5.8 2.2]\n",
            " [7.6 3.  6.6 2.1]\n",
            " [4.9 2.5 4.5 1.7]\n",
            " [7.3 2.9 6.3 1.8]\n",
            " [6.7 2.5 5.8 1.8]\n",
            " [7.2 3.6 6.1 2.5]\n",
            " [6.5 3.2 5.1 2. ]\n",
            " [6.4 2.7 5.3 1.9]\n",
            " [6.8 3.  5.5 2.1]\n",
            " [5.7 2.5 5.  2. ]\n",
            " [5.8 2.8 5.1 2.4]\n",
            " [6.4 3.2 5.3 2.3]\n",
            " [6.5 3.  5.5 1.8]\n",
            " [7.7 3.8 6.7 2.2]\n",
            " [7.7 2.6 6.9 2.3]\n",
            " [6.  2.2 5.  1.5]\n",
            " [6.9 3.2 5.7 2.3]\n",
            " [5.6 2.8 4.9 2. ]\n",
            " [7.7 2.8 6.7 2. ]\n",
            " [6.3 2.7 4.9 1.8]\n",
            " [6.7 3.3 5.7 2.1]\n",
            " [7.2 3.2 6.  1.8]\n",
            " [6.2 2.8 4.8 1.8]\n",
            " [6.1 3.  4.9 1.8]\n",
            " [6.4 2.8 5.6 2.1]\n",
            " [7.2 3.  5.8 1.6]\n",
            " [7.4 2.8 6.1 1.9]\n",
            " [7.9 3.8 6.4 2. ]\n",
            " [6.4 2.8 5.6 2.2]\n",
            " [6.3 2.8 5.1 1.5]\n",
            " [6.1 2.6 5.6 1.4]\n",
            " [7.7 3.  6.1 2.3]\n",
            " [6.3 3.4 5.6 2.4]\n",
            " [6.4 3.1 5.5 1.8]\n",
            " [6.  3.  4.8 1.8]\n",
            " [6.9 3.1 5.4 2.1]\n",
            " [6.7 3.1 5.6 2.4]\n",
            " [6.9 3.1 5.1 2.3]\n",
            " [5.8 2.7 5.1 1.9]\n",
            " [6.8 3.2 5.9 2.3]\n",
            " [6.7 3.3 5.7 2.5]\n",
            " [6.7 3.  5.2 2.3]\n",
            " [6.3 2.5 5.  1.9]\n",
            " [6.5 3.  5.2 2. ]\n",
            " [6.2 3.4 5.4 2.3]\n",
            " [5.9 3.  5.1 1.8]]\n",
            "line 1\n",
            "[4.90784314 3.35098039 1.43529412 0.23921569]\n",
            "hehe  False\n",
            "line 2\n",
            "[(array([[5.1, 3.5, 1.4, 0.2],\n",
            "       [4.9, 3. , 1.4, 0.2],\n",
            "       [4.7, 3.2, 1.3, 0.2],\n",
            "       [4.6, 3.1, 1.5, 0.2],\n",
            "       [5. , 3.6, 1.4, 0.2],\n",
            "       [5.4, 3.9, 1.7, 0.4],\n",
            "       [4.6, 3.4, 1.4, 0.3],\n",
            "       [5. , 3.4, 1.5, 0.2],\n",
            "       [4.4, 2.9, 1.4, 0.2],\n",
            "       [4.9, 3.1, 1.5, 0.1],\n",
            "       [5.4, 3.7, 1.5, 0.2],\n",
            "       [4.8, 3.4, 1.6, 0.2],\n",
            "       [4.8, 3. , 1.4, 0.1],\n",
            "       [4.3, 3. , 1.1, 0.1],\n",
            "       [5.8, 4. , 1.2, 0.2],\n",
            "       [5.7, 4.4, 1.5, 0.4],\n",
            "       [5.4, 3.9, 1.3, 0.4],\n",
            "       [5.1, 3.5, 1.4, 0.3],\n",
            "       [5.7, 3.8, 1.7, 0.3],\n",
            "       [5.1, 3.8, 1.5, 0.3],\n",
            "       [5.4, 3.4, 1.7, 0.2],\n",
            "       [5.1, 3.7, 1.5, 0.4],\n",
            "       [4.6, 3.6, 1. , 0.2],\n",
            "       [5.1, 3.3, 1.7, 0.5],\n",
            "       [4.8, 3.4, 1.9, 0.2],\n",
            "       [5. , 3. , 1.6, 0.2],\n",
            "       [5. , 3.4, 1.6, 0.4],\n",
            "       [5.2, 3.5, 1.5, 0.2],\n",
            "       [5.2, 3.4, 1.4, 0.2],\n",
            "       [4.7, 3.2, 1.6, 0.2],\n",
            "       [4.8, 3.1, 1.6, 0.2],\n",
            "       [5.4, 3.4, 1.5, 0.4],\n",
            "       [5.2, 4.1, 1.5, 0.1],\n",
            "       [5.5, 4.2, 1.4, 0.2],\n",
            "       [4.9, 3.1, 1.5, 0.1],\n",
            "       [5. , 3.2, 1.2, 0.2],\n",
            "       [5.5, 3.5, 1.3, 0.2],\n",
            "       [4.9, 3.1, 1.5, 0.1],\n",
            "       [4.4, 3. , 1.3, 0.2],\n",
            "       [5.1, 3.4, 1.5, 0.2],\n",
            "       [5. , 3.5, 1.3, 0.3],\n",
            "       [4.5, 2.3, 1.3, 0.3],\n",
            "       [4.4, 3.2, 1.3, 0.2],\n",
            "       [5. , 3.5, 1.6, 0.6],\n",
            "       [5.1, 3.8, 1.9, 0.4],\n",
            "       [4.8, 3. , 1.4, 0.3],\n",
            "       [5.1, 3.8, 1.6, 0.2],\n",
            "       [4.6, 3.2, 1.4, 0.2],\n",
            "       [5.3, 3.7, 1.5, 0.2],\n",
            "       [5. , 3.3, 1.4, 0.2],\n",
            "       [7. , 3.2, 4.7, 1.4],\n",
            "       [6.4, 3.2, 4.5, 1.5],\n",
            "       [6.9, 3.1, 4.9, 1.5],\n",
            "       [5.5, 2.3, 4. , 1.3],\n",
            "       [6.5, 2.8, 4.6, 1.5],\n",
            "       [5.7, 2.8, 4.5, 1.3],\n",
            "       [6.3, 3.3, 4.7, 1.6],\n",
            "       [4.9, 2.4, 3.3, 1. ],\n",
            "       [6.6, 2.9, 4.6, 1.3],\n",
            "       [5.2, 2.7, 3.9, 1.4],\n",
            "       [5. , 2. , 3.5, 1. ],\n",
            "       [5.9, 3. , 4.2, 1.5],\n",
            "       [6. , 2.2, 4. , 1. ],\n",
            "       [6.1, 2.9, 4.7, 1.4],\n",
            "       [5.6, 2.9, 3.6, 1.3],\n",
            "       [6.7, 3.1, 4.4, 1.4],\n",
            "       [5.6, 3. , 4.5, 1.5],\n",
            "       [5.8, 2.7, 4.1, 1. ],\n",
            "       [6.2, 2.2, 4.5, 1.5],\n",
            "       [5.6, 2.5, 3.9, 1.1],\n",
            "       [5.9, 3.2, 4.8, 1.8],\n",
            "       [6.1, 2.8, 4. , 1.3],\n",
            "       [6.3, 2.5, 4.9, 1.5],\n",
            "       [6.1, 2.8, 4.7, 1.2],\n",
            "       [6.4, 2.9, 4.3, 1.3],\n",
            "       [6.6, 3. , 4.4, 1.4],\n",
            "       [6.8, 2.8, 4.8, 1.4],\n",
            "       [6.7, 3. , 5. , 1.7],\n",
            "       [6. , 2.9, 4.5, 1.5],\n",
            "       [5.7, 2.6, 3.5, 1. ],\n",
            "       [5.5, 2.4, 3.8, 1.1],\n",
            "       [5.5, 2.4, 3.7, 1. ],\n",
            "       [5.8, 2.7, 3.9, 1.2],\n",
            "       [6. , 2.7, 5.1, 1.6],\n",
            "       [5.4, 3. , 4.5, 1.5],\n",
            "       [6. , 3.4, 4.5, 1.6],\n",
            "       [6.7, 3.1, 4.7, 1.5],\n",
            "       [6.3, 2.3, 4.4, 1.3],\n",
            "       [5.6, 3. , 4.1, 1.3],\n",
            "       [5.5, 2.5, 4. , 1.3],\n",
            "       [5.5, 2.6, 4.4, 1.2],\n",
            "       [6.1, 3. , 4.6, 1.4],\n",
            "       [5.8, 2.6, 4. , 1.2],\n",
            "       [5. , 2.3, 3.3, 1. ],\n",
            "       [5.6, 2.7, 4.2, 1.3],\n",
            "       [5.7, 3. , 4.2, 1.2],\n",
            "       [5.7, 2.9, 4.2, 1.3],\n",
            "       [6.2, 2.9, 4.3, 1.3],\n",
            "       [5.1, 2.5, 3. , 1.1],\n",
            "       [5.7, 2.8, 4.1, 1.3],\n",
            "       [6.3, 3.3, 6. , 2.5],\n",
            "       [5.8, 2.7, 5.1, 1.9],\n",
            "       [7.1, 3. , 5.9, 2.1],\n",
            "       [6.3, 2.9, 5.6, 1.8],\n",
            "       [6.5, 3. , 5.8, 2.2],\n",
            "       [7.6, 3. , 6.6, 2.1],\n",
            "       [4.9, 2.5, 4.5, 1.7],\n",
            "       [7.3, 2.9, 6.3, 1.8],\n",
            "       [6.7, 2.5, 5.8, 1.8],\n",
            "       [7.2, 3.6, 6.1, 2.5],\n",
            "       [6.5, 3.2, 5.1, 2. ],\n",
            "       [6.4, 2.7, 5.3, 1.9],\n",
            "       [6.8, 3. , 5.5, 2.1],\n",
            "       [5.7, 2.5, 5. , 2. ],\n",
            "       [5.8, 2.8, 5.1, 2.4],\n",
            "       [6.4, 3.2, 5.3, 2.3],\n",
            "       [6.5, 3. , 5.5, 1.8],\n",
            "       [7.7, 3.8, 6.7, 2.2],\n",
            "       [7.7, 2.6, 6.9, 2.3],\n",
            "       [6. , 2.2, 5. , 1.5],\n",
            "       [6.9, 3.2, 5.7, 2.3],\n",
            "       [5.6, 2.8, 4.9, 2. ],\n",
            "       [7.7, 2.8, 6.7, 2. ],\n",
            "       [6.3, 2.7, 4.9, 1.8],\n",
            "       [6.7, 3.3, 5.7, 2.1],\n",
            "       [7.2, 3.2, 6. , 1.8],\n",
            "       [6.2, 2.8, 4.8, 1.8],\n",
            "       [6.1, 3. , 4.9, 1.8],\n",
            "       [6.4, 2.8, 5.6, 2.1],\n",
            "       [7.2, 3. , 5.8, 1.6],\n",
            "       [7.4, 2.8, 6.1, 1.9],\n",
            "       [7.9, 3.8, 6.4, 2. ],\n",
            "       [6.4, 2.8, 5.6, 2.2],\n",
            "       [6.3, 2.8, 5.1, 1.5],\n",
            "       [6.1, 2.6, 5.6, 1.4],\n",
            "       [7.7, 3. , 6.1, 2.3],\n",
            "       [6.3, 3.4, 5.6, 2.4],\n",
            "       [6.4, 3.1, 5.5, 1.8],\n",
            "       [6. , 3. , 4.8, 1.8],\n",
            "       [6.9, 3.1, 5.4, 2.1],\n",
            "       [6.7, 3.1, 5.6, 2.4],\n",
            "       [6.9, 3.1, 5.1, 2.3],\n",
            "       [5.8, 2.7, 5.1, 1.9],\n",
            "       [6.8, 3.2, 5.9, 2.3],\n",
            "       [6.7, 3.3, 5.7, 2.5],\n",
            "       [6.7, 3. , 5.2, 2.3],\n",
            "       [6.3, 2.5, 5. , 1.9],\n",
            "       [6.5, 3. , 5.2, 2. ],\n",
            "       [6.2, 3.4, 5.4, 2.3],\n",
            "       [5.9, 3. , 5.1, 1.8]]), array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=int64))]\n",
            "[(array([[5.1, 3.5, 1.4, 0.2],\n",
            "       [4.9, 3. , 1.4, 0.2],\n",
            "       [4.7, 3.2, 1.3, 0.2],\n",
            "       [4.6, 3.1, 1.5, 0.2],\n",
            "       [5. , 3.6, 1.4, 0.2],\n",
            "       [5.4, 3.9, 1.7, 0.4],\n",
            "       [4.6, 3.4, 1.4, 0.3],\n",
            "       [5. , 3.4, 1.5, 0.2],\n",
            "       [4.4, 2.9, 1.4, 0.2],\n",
            "       [4.9, 3.1, 1.5, 0.1],\n",
            "       [5.4, 3.7, 1.5, 0.2],\n",
            "       [4.8, 3.4, 1.6, 0.2],\n",
            "       [4.8, 3. , 1.4, 0.1],\n",
            "       [4.3, 3. , 1.1, 0.1],\n",
            "       [5.8, 4. , 1.2, 0.2],\n",
            "       [5.7, 4.4, 1.5, 0.4],\n",
            "       [5.4, 3.9, 1.3, 0.4],\n",
            "       [5.1, 3.5, 1.4, 0.3],\n",
            "       [5.7, 3.8, 1.7, 0.3],\n",
            "       [5.1, 3.8, 1.5, 0.3],\n",
            "       [5.4, 3.4, 1.7, 0.2],\n",
            "       [5.1, 3.7, 1.5, 0.4],\n",
            "       [4.6, 3.6, 1. , 0.2],\n",
            "       [5.1, 3.3, 1.7, 0.5],\n",
            "       [4.8, 3.4, 1.9, 0.2],\n",
            "       [5. , 3. , 1.6, 0.2],\n",
            "       [5. , 3.4, 1.6, 0.4],\n",
            "       [5.2, 3.5, 1.5, 0.2],\n",
            "       [5.2, 3.4, 1.4, 0.2],\n",
            "       [4.7, 3.2, 1.6, 0.2],\n",
            "       [4.8, 3.1, 1.6, 0.2],\n",
            "       [5.4, 3.4, 1.5, 0.4],\n",
            "       [5.2, 4.1, 1.5, 0.1],\n",
            "       [5.5, 4.2, 1.4, 0.2],\n",
            "       [4.9, 3.1, 1.5, 0.1],\n",
            "       [5. , 3.2, 1.2, 0.2],\n",
            "       [5.5, 3.5, 1.3, 0.2],\n",
            "       [4.9, 3.1, 1.5, 0.1],\n",
            "       [4.4, 3. , 1.3, 0.2],\n",
            "       [5.1, 3.4, 1.5, 0.2],\n",
            "       [5. , 3.5, 1.3, 0.3],\n",
            "       [4.5, 2.3, 1.3, 0.3],\n",
            "       [4.4, 3.2, 1.3, 0.2],\n",
            "       [5. , 3.5, 1.6, 0.6],\n",
            "       [5.1, 3.8, 1.9, 0.4],\n",
            "       [4.8, 3. , 1.4, 0.3],\n",
            "       [5.1, 3.8, 1.6, 0.2],\n",
            "       [4.6, 3.2, 1.4, 0.2],\n",
            "       [5.3, 3.7, 1.5, 0.2],\n",
            "       [5. , 3.3, 1.4, 0.2],\n",
            "       [7. , 3.2, 4.7, 1.4],\n",
            "       [6.4, 3.2, 4.5, 1.5],\n",
            "       [6.9, 3.1, 4.9, 1.5],\n",
            "       [5.5, 2.3, 4. , 1.3],\n",
            "       [6.5, 2.8, 4.6, 1.5],\n",
            "       [5.7, 2.8, 4.5, 1.3],\n",
            "       [6.3, 3.3, 4.7, 1.6],\n",
            "       [4.9, 2.4, 3.3, 1. ],\n",
            "       [6.6, 2.9, 4.6, 1.3],\n",
            "       [5.2, 2.7, 3.9, 1.4],\n",
            "       [5. , 2. , 3.5, 1. ],\n",
            "       [5.9, 3. , 4.2, 1.5],\n",
            "       [6. , 2.2, 4. , 1. ],\n",
            "       [6.1, 2.9, 4.7, 1.4],\n",
            "       [5.6, 2.9, 3.6, 1.3],\n",
            "       [6.7, 3.1, 4.4, 1.4],\n",
            "       [5.6, 3. , 4.5, 1.5],\n",
            "       [5.8, 2.7, 4.1, 1. ],\n",
            "       [6.2, 2.2, 4.5, 1.5],\n",
            "       [5.6, 2.5, 3.9, 1.1],\n",
            "       [5.9, 3.2, 4.8, 1.8],\n",
            "       [6.1, 2.8, 4. , 1.3],\n",
            "       [6.3, 2.5, 4.9, 1.5],\n",
            "       [6.1, 2.8, 4.7, 1.2],\n",
            "       [6.4, 2.9, 4.3, 1.3],\n",
            "       [6.6, 3. , 4.4, 1.4],\n",
            "       [6.8, 2.8, 4.8, 1.4],\n",
            "       [6.7, 3. , 5. , 1.7],\n",
            "       [6. , 2.9, 4.5, 1.5],\n",
            "       [5.7, 2.6, 3.5, 1. ],\n",
            "       [5.5, 2.4, 3.8, 1.1],\n",
            "       [5.5, 2.4, 3.7, 1. ],\n",
            "       [5.8, 2.7, 3.9, 1.2],\n",
            "       [6. , 2.7, 5.1, 1.6],\n",
            "       [5.4, 3. , 4.5, 1.5],\n",
            "       [6. , 3.4, 4.5, 1.6],\n",
            "       [6.7, 3.1, 4.7, 1.5],\n",
            "       [6.3, 2.3, 4.4, 1.3],\n",
            "       [5.6, 3. , 4.1, 1.3],\n",
            "       [5.5, 2.5, 4. , 1.3],\n",
            "       [5.5, 2.6, 4.4, 1.2],\n",
            "       [6.1, 3. , 4.6, 1.4],\n",
            "       [5.8, 2.6, 4. , 1.2],\n",
            "       [5. , 2.3, 3.3, 1. ],\n",
            "       [5.6, 2.7, 4.2, 1.3],\n",
            "       [5.7, 3. , 4.2, 1.2],\n",
            "       [5.7, 2.9, 4.2, 1.3],\n",
            "       [6.2, 2.9, 4.3, 1.3],\n",
            "       [5.1, 2.5, 3. , 1.1],\n",
            "       [5.7, 2.8, 4.1, 1.3],\n",
            "       [6.3, 3.3, 6. , 2.5],\n",
            "       [5.8, 2.7, 5.1, 1.9],\n",
            "       [7.1, 3. , 5.9, 2.1],\n",
            "       [6.3, 2.9, 5.6, 1.8],\n",
            "       [6.5, 3. , 5.8, 2.2],\n",
            "       [7.6, 3. , 6.6, 2.1],\n",
            "       [4.9, 2.5, 4.5, 1.7],\n",
            "       [7.3, 2.9, 6.3, 1.8],\n",
            "       [6.7, 2.5, 5.8, 1.8],\n",
            "       [7.2, 3.6, 6.1, 2.5],\n",
            "       [6.5, 3.2, 5.1, 2. ],\n",
            "       [6.4, 2.7, 5.3, 1.9],\n",
            "       [6.8, 3. , 5.5, 2.1],\n",
            "       [5.7, 2.5, 5. , 2. ],\n",
            "       [5.8, 2.8, 5.1, 2.4],\n",
            "       [6.4, 3.2, 5.3, 2.3],\n",
            "       [6.5, 3. , 5.5, 1.8],\n",
            "       [7.7, 3.8, 6.7, 2.2],\n",
            "       [7.7, 2.6, 6.9, 2.3],\n",
            "       [6. , 2.2, 5. , 1.5],\n",
            "       [6.9, 3.2, 5.7, 2.3],\n",
            "       [5.6, 2.8, 4.9, 2. ],\n",
            "       [7.7, 2.8, 6.7, 2. ],\n",
            "       [6.3, 2.7, 4.9, 1.8],\n",
            "       [6.7, 3.3, 5.7, 2.1],\n",
            "       [7.2, 3.2, 6. , 1.8],\n",
            "       [6.2, 2.8, 4.8, 1.8],\n",
            "       [6.1, 3. , 4.9, 1.8],\n",
            "       [6.4, 2.8, 5.6, 2.1],\n",
            "       [7.2, 3. , 5.8, 1.6],\n",
            "       [7.4, 2.8, 6.1, 1.9],\n",
            "       [7.9, 3.8, 6.4, 2. ],\n",
            "       [6.4, 2.8, 5.6, 2.2],\n",
            "       [6.3, 2.8, 5.1, 1.5],\n",
            "       [6.1, 2.6, 5.6, 1.4],\n",
            "       [7.7, 3. , 6.1, 2.3],\n",
            "       [6.3, 3.4, 5.6, 2.4],\n",
            "       [6.4, 3.1, 5.5, 1.8],\n",
            "       [6. , 3. , 4.8, 1.8],\n",
            "       [6.9, 3.1, 5.4, 2.1],\n",
            "       [6.7, 3.1, 5.6, 2.4],\n",
            "       [6.9, 3.1, 5.1, 2.3],\n",
            "       [5.8, 2.7, 5.1, 1.9],\n",
            "       [6.8, 3.2, 5.9, 2.3],\n",
            "       [6.7, 3.3, 5.7, 2.5],\n",
            "       [6.7, 3. , 5.2, 2.3],\n",
            "       [6.3, 2.5, 5. , 1.9],\n",
            "       [6.5, 3. , 5.2, 2. ],\n",
            "       [6.2, 3.4, 5.4, 2.3],\n",
            "       [5.9, 3. , 5.1, 1.8]]), array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=int64)), (array([[6.4, 3.2, 4.5, 1.5],\n",
            "       [6.9, 3.1, 4.9, 1.5],\n",
            "       [5.5, 2.3, 4. , 1.3],\n",
            "       [6.5, 2.8, 4.6, 1.5],\n",
            "       [5.7, 2.8, 4.5, 1.3],\n",
            "       [6.3, 3.3, 4.7, 1.6],\n",
            "       [4.9, 2.4, 3.3, 1. ],\n",
            "       [6.6, 2.9, 4.6, 1.3],\n",
            "       [5.2, 2.7, 3.9, 1.4],\n",
            "       [5. , 2. , 3.5, 1. ],\n",
            "       [5.9, 3. , 4.2, 1.5],\n",
            "       [6. , 2.2, 4. , 1. ],\n",
            "       [6.1, 2.9, 4.7, 1.4],\n",
            "       [5.6, 2.9, 3.6, 1.3],\n",
            "       [6.7, 3.1, 4.4, 1.4],\n",
            "       [5.6, 3. , 4.5, 1.5],\n",
            "       [5.8, 2.7, 4.1, 1. ],\n",
            "       [6.2, 2.2, 4.5, 1.5],\n",
            "       [5.6, 2.5, 3.9, 1.1],\n",
            "       [5.9, 3.2, 4.8, 1.8],\n",
            "       [6.1, 2.8, 4. , 1.3],\n",
            "       [6.3, 2.5, 4.9, 1.5],\n",
            "       [6.1, 2.8, 4.7, 1.2],\n",
            "       [6.4, 2.9, 4.3, 1.3],\n",
            "       [6.6, 3. , 4.4, 1.4],\n",
            "       [6.8, 2.8, 4.8, 1.4],\n",
            "       [6.7, 3. , 5. , 1.7],\n",
            "       [6. , 2.9, 4.5, 1.5],\n",
            "       [5.7, 2.6, 3.5, 1. ],\n",
            "       [5.5, 2.4, 3.8, 1.1],\n",
            "       [5.5, 2.4, 3.7, 1. ],\n",
            "       [5.8, 2.7, 3.9, 1.2],\n",
            "       [6. , 2.7, 5.1, 1.6],\n",
            "       [5.4, 3. , 4.5, 1.5],\n",
            "       [6. , 3.4, 4.5, 1.6],\n",
            "       [6.7, 3.1, 4.7, 1.5],\n",
            "       [6.3, 2.3, 4.4, 1.3],\n",
            "       [5.6, 3. , 4.1, 1.3],\n",
            "       [5.5, 2.5, 4. , 1.3],\n",
            "       [5.5, 2.6, 4.4, 1.2],\n",
            "       [6.1, 3. , 4.6, 1.4],\n",
            "       [5.8, 2.6, 4. , 1.2],\n",
            "       [5. , 2.3, 3.3, 1. ],\n",
            "       [5.6, 2.7, 4.2, 1.3],\n",
            "       [5.7, 3. , 4.2, 1.2],\n",
            "       [5.7, 2.9, 4.2, 1.3],\n",
            "       [6.2, 2.9, 4.3, 1.3],\n",
            "       [5.1, 2.5, 3. , 1.1],\n",
            "       [5.7, 2.8, 4.1, 1.3],\n",
            "       [6.3, 3.3, 6. , 2.5],\n",
            "       [5.8, 2.7, 5.1, 1.9],\n",
            "       [7.1, 3. , 5.9, 2.1],\n",
            "       [6.3, 2.9, 5.6, 1.8],\n",
            "       [6.5, 3. , 5.8, 2.2],\n",
            "       [7.6, 3. , 6.6, 2.1],\n",
            "       [4.9, 2.5, 4.5, 1.7],\n",
            "       [7.3, 2.9, 6.3, 1.8],\n",
            "       [6.7, 2.5, 5.8, 1.8],\n",
            "       [7.2, 3.6, 6.1, 2.5],\n",
            "       [6.5, 3.2, 5.1, 2. ],\n",
            "       [6.4, 2.7, 5.3, 1.9],\n",
            "       [6.8, 3. , 5.5, 2.1],\n",
            "       [5.7, 2.5, 5. , 2. ],\n",
            "       [5.8, 2.8, 5.1, 2.4],\n",
            "       [6.4, 3.2, 5.3, 2.3],\n",
            "       [6.5, 3. , 5.5, 1.8],\n",
            "       [7.7, 3.8, 6.7, 2.2],\n",
            "       [7.7, 2.6, 6.9, 2.3],\n",
            "       [6. , 2.2, 5. , 1.5],\n",
            "       [6.9, 3.2, 5.7, 2.3],\n",
            "       [5.6, 2.8, 4.9, 2. ],\n",
            "       [7.7, 2.8, 6.7, 2. ],\n",
            "       [6.3, 2.7, 4.9, 1.8],\n",
            "       [6.7, 3.3, 5.7, 2.1],\n",
            "       [7.2, 3.2, 6. , 1.8],\n",
            "       [6.2, 2.8, 4.8, 1.8],\n",
            "       [6.1, 3. , 4.9, 1.8],\n",
            "       [6.4, 2.8, 5.6, 2.1],\n",
            "       [7.2, 3. , 5.8, 1.6],\n",
            "       [7.4, 2.8, 6.1, 1.9],\n",
            "       [7.9, 3.8, 6.4, 2. ],\n",
            "       [6.4, 2.8, 5.6, 2.2],\n",
            "       [6.3, 2.8, 5.1, 1.5],\n",
            "       [6.1, 2.6, 5.6, 1.4],\n",
            "       [7.7, 3. , 6.1, 2.3],\n",
            "       [6.3, 3.4, 5.6, 2.4],\n",
            "       [6.4, 3.1, 5.5, 1.8],\n",
            "       [6. , 3. , 4.8, 1.8],\n",
            "       [6.9, 3.1, 5.4, 2.1],\n",
            "       [6.7, 3.1, 5.6, 2.4],\n",
            "       [6.9, 3.1, 5.1, 2.3],\n",
            "       [5.8, 2.7, 5.1, 1.9],\n",
            "       [6.8, 3.2, 5.9, 2.3],\n",
            "       [6.7, 3.3, 5.7, 2.5],\n",
            "       [6.7, 3. , 5.2, 2.3],\n",
            "       [6.3, 2.5, 5. , 1.9],\n",
            "       [6.5, 3. , 5.2, 2. ],\n",
            "       [6.2, 3.4, 5.4, 2.3],\n",
            "       [5.9, 3. , 5.1, 1.8]]), array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=int64))]\n",
            "minority_class_label 1\n",
            "resampled [(array([[5.1, 3.5, 1.4, 0.2],\n",
            "       [4.9, 3. , 1.4, 0.2],\n",
            "       [4.7, 3.2, 1.3, 0.2],\n",
            "       [4.6, 3.1, 1.5, 0.2],\n",
            "       [5. , 3.6, 1.4, 0.2],\n",
            "       [5.4, 3.9, 1.7, 0.4],\n",
            "       [4.6, 3.4, 1.4, 0.3],\n",
            "       [5. , 3.4, 1.5, 0.2],\n",
            "       [4.4, 2.9, 1.4, 0.2],\n",
            "       [4.9, 3.1, 1.5, 0.1],\n",
            "       [5.4, 3.7, 1.5, 0.2],\n",
            "       [4.8, 3.4, 1.6, 0.2],\n",
            "       [4.8, 3. , 1.4, 0.1],\n",
            "       [4.3, 3. , 1.1, 0.1],\n",
            "       [5.8, 4. , 1.2, 0.2],\n",
            "       [5.7, 4.4, 1.5, 0.4],\n",
            "       [5.4, 3.9, 1.3, 0.4],\n",
            "       [5.1, 3.5, 1.4, 0.3],\n",
            "       [5.7, 3.8, 1.7, 0.3],\n",
            "       [5.1, 3.8, 1.5, 0.3],\n",
            "       [5.4, 3.4, 1.7, 0.2],\n",
            "       [5.1, 3.7, 1.5, 0.4],\n",
            "       [4.6, 3.6, 1. , 0.2],\n",
            "       [5.1, 3.3, 1.7, 0.5],\n",
            "       [4.8, 3.4, 1.9, 0.2],\n",
            "       [5. , 3. , 1.6, 0.2],\n",
            "       [5. , 3.4, 1.6, 0.4],\n",
            "       [5.2, 3.5, 1.5, 0.2],\n",
            "       [5.2, 3.4, 1.4, 0.2],\n",
            "       [4.7, 3.2, 1.6, 0.2],\n",
            "       [4.8, 3.1, 1.6, 0.2],\n",
            "       [5.4, 3.4, 1.5, 0.4],\n",
            "       [5.2, 4.1, 1.5, 0.1],\n",
            "       [5.5, 4.2, 1.4, 0.2],\n",
            "       [4.9, 3.1, 1.5, 0.1],\n",
            "       [5. , 3.2, 1.2, 0.2],\n",
            "       [5.5, 3.5, 1.3, 0.2],\n",
            "       [4.9, 3.1, 1.5, 0.1],\n",
            "       [4.4, 3. , 1.3, 0.2],\n",
            "       [5.1, 3.4, 1.5, 0.2],\n",
            "       [5. , 3.5, 1.3, 0.3],\n",
            "       [4.5, 2.3, 1.3, 0.3],\n",
            "       [4.4, 3.2, 1.3, 0.2],\n",
            "       [5. , 3.5, 1.6, 0.6],\n",
            "       [5.1, 3.8, 1.9, 0.4],\n",
            "       [4.8, 3. , 1.4, 0.3],\n",
            "       [5.1, 3.8, 1.6, 0.2],\n",
            "       [4.6, 3.2, 1.4, 0.2],\n",
            "       [5.3, 3.7, 1.5, 0.2],\n",
            "       [5. , 3.3, 1.4, 0.2],\n",
            "       [7. , 3.2, 4.7, 1.4],\n",
            "       [6.4, 3.2, 4.5, 1.5],\n",
            "       [6.9, 3.1, 4.9, 1.5],\n",
            "       [5.5, 2.3, 4. , 1.3],\n",
            "       [6.5, 2.8, 4.6, 1.5],\n",
            "       [5.7, 2.8, 4.5, 1.3],\n",
            "       [6.3, 3.3, 4.7, 1.6],\n",
            "       [4.9, 2.4, 3.3, 1. ],\n",
            "       [6.6, 2.9, 4.6, 1.3],\n",
            "       [5.2, 2.7, 3.9, 1.4],\n",
            "       [5. , 2. , 3.5, 1. ],\n",
            "       [5.9, 3. , 4.2, 1.5],\n",
            "       [6. , 2.2, 4. , 1. ],\n",
            "       [6.1, 2.9, 4.7, 1.4],\n",
            "       [5.6, 2.9, 3.6, 1.3],\n",
            "       [6.7, 3.1, 4.4, 1.4],\n",
            "       [5.6, 3. , 4.5, 1.5],\n",
            "       [5.8, 2.7, 4.1, 1. ],\n",
            "       [6.2, 2.2, 4.5, 1.5],\n",
            "       [5.6, 2.5, 3.9, 1.1],\n",
            "       [5.9, 3.2, 4.8, 1.8],\n",
            "       [6.1, 2.8, 4. , 1.3],\n",
            "       [6.3, 2.5, 4.9, 1.5],\n",
            "       [6.1, 2.8, 4.7, 1.2],\n",
            "       [6.4, 2.9, 4.3, 1.3],\n",
            "       [6.6, 3. , 4.4, 1.4],\n",
            "       [6.8, 2.8, 4.8, 1.4],\n",
            "       [6.7, 3. , 5. , 1.7],\n",
            "       [6. , 2.9, 4.5, 1.5],\n",
            "       [5.7, 2.6, 3.5, 1. ],\n",
            "       [5.5, 2.4, 3.8, 1.1],\n",
            "       [5.5, 2.4, 3.7, 1. ],\n",
            "       [5.8, 2.7, 3.9, 1.2],\n",
            "       [6. , 2.7, 5.1, 1.6],\n",
            "       [5.4, 3. , 4.5, 1.5],\n",
            "       [6. , 3.4, 4.5, 1.6],\n",
            "       [6.7, 3.1, 4.7, 1.5],\n",
            "       [6.3, 2.3, 4.4, 1.3],\n",
            "       [5.6, 3. , 4.1, 1.3],\n",
            "       [5.5, 2.5, 4. , 1.3],\n",
            "       [5.5, 2.6, 4.4, 1.2],\n",
            "       [6.1, 3. , 4.6, 1.4],\n",
            "       [5.8, 2.6, 4. , 1.2],\n",
            "       [5. , 2.3, 3.3, 1. ],\n",
            "       [5.6, 2.7, 4.2, 1.3],\n",
            "       [5.7, 3. , 4.2, 1.2],\n",
            "       [5.7, 2.9, 4.2, 1.3],\n",
            "       [6.2, 2.9, 4.3, 1.3],\n",
            "       [5.1, 2.5, 3. , 1.1],\n",
            "       [5.7, 2.8, 4.1, 1.3],\n",
            "       [6.3, 3.3, 6. , 2.5],\n",
            "       [5.8, 2.7, 5.1, 1.9],\n",
            "       [7.1, 3. , 5.9, 2.1],\n",
            "       [6.3, 2.9, 5.6, 1.8],\n",
            "       [6.5, 3. , 5.8, 2.2],\n",
            "       [7.6, 3. , 6.6, 2.1],\n",
            "       [4.9, 2.5, 4.5, 1.7],\n",
            "       [7.3, 2.9, 6.3, 1.8],\n",
            "       [6.7, 2.5, 5.8, 1.8],\n",
            "       [7.2, 3.6, 6.1, 2.5],\n",
            "       [6.5, 3.2, 5.1, 2. ],\n",
            "       [6.4, 2.7, 5.3, 1.9],\n",
            "       [6.8, 3. , 5.5, 2.1],\n",
            "       [5.7, 2.5, 5. , 2. ],\n",
            "       [5.8, 2.8, 5.1, 2.4],\n",
            "       [6.4, 3.2, 5.3, 2.3],\n",
            "       [6.5, 3. , 5.5, 1.8],\n",
            "       [7.7, 3.8, 6.7, 2.2],\n",
            "       [7.7, 2.6, 6.9, 2.3],\n",
            "       [6. , 2.2, 5. , 1.5],\n",
            "       [6.9, 3.2, 5.7, 2.3],\n",
            "       [5.6, 2.8, 4.9, 2. ],\n",
            "       [7.7, 2.8, 6.7, 2. ],\n",
            "       [6.3, 2.7, 4.9, 1.8],\n",
            "       [6.7, 3.3, 5.7, 2.1],\n",
            "       [7.2, 3.2, 6. , 1.8],\n",
            "       [6.2, 2.8, 4.8, 1.8],\n",
            "       [6.1, 3. , 4.9, 1.8],\n",
            "       [6.4, 2.8, 5.6, 2.1],\n",
            "       [7.2, 3. , 5.8, 1.6],\n",
            "       [7.4, 2.8, 6.1, 1.9],\n",
            "       [7.9, 3.8, 6.4, 2. ],\n",
            "       [6.4, 2.8, 5.6, 2.2],\n",
            "       [6.3, 2.8, 5.1, 1.5],\n",
            "       [6.1, 2.6, 5.6, 1.4],\n",
            "       [7.7, 3. , 6.1, 2.3],\n",
            "       [6.3, 3.4, 5.6, 2.4],\n",
            "       [6.4, 3.1, 5.5, 1.8],\n",
            "       [6. , 3. , 4.8, 1.8],\n",
            "       [6.9, 3.1, 5.4, 2.1],\n",
            "       [6.7, 3.1, 5.6, 2.4],\n",
            "       [6.9, 3.1, 5.1, 2.3],\n",
            "       [5.8, 2.7, 5.1, 1.9],\n",
            "       [6.8, 3.2, 5.9, 2.3],\n",
            "       [6.7, 3.3, 5.7, 2.5],\n",
            "       [6.7, 3. , 5.2, 2.3],\n",
            "       [6.3, 2.5, 5. , 1.9],\n",
            "       [6.5, 3. , 5.2, 2. ],\n",
            "       [6.2, 3.4, 5.4, 2.3],\n",
            "       [5.9, 3. , 5.1, 1.8]]), array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=int64)), (array([[6.4, 3.2, 4.5, 1.5],\n",
            "       [6.9, 3.1, 4.9, 1.5],\n",
            "       [5.5, 2.3, 4. , 1.3],\n",
            "       [6.5, 2.8, 4.6, 1.5],\n",
            "       [5.7, 2.8, 4.5, 1.3],\n",
            "       [6.3, 3.3, 4.7, 1.6],\n",
            "       [4.9, 2.4, 3.3, 1. ],\n",
            "       [6.6, 2.9, 4.6, 1.3],\n",
            "       [5.2, 2.7, 3.9, 1.4],\n",
            "       [5. , 2. , 3.5, 1. ],\n",
            "       [5.9, 3. , 4.2, 1.5],\n",
            "       [6. , 2.2, 4. , 1. ],\n",
            "       [6.1, 2.9, 4.7, 1.4],\n",
            "       [5.6, 2.9, 3.6, 1.3],\n",
            "       [6.7, 3.1, 4.4, 1.4],\n",
            "       [5.6, 3. , 4.5, 1.5],\n",
            "       [5.8, 2.7, 4.1, 1. ],\n",
            "       [6.2, 2.2, 4.5, 1.5],\n",
            "       [5.6, 2.5, 3.9, 1.1],\n",
            "       [5.9, 3.2, 4.8, 1.8],\n",
            "       [6.1, 2.8, 4. , 1.3],\n",
            "       [6.3, 2.5, 4.9, 1.5],\n",
            "       [6.1, 2.8, 4.7, 1.2],\n",
            "       [6.4, 2.9, 4.3, 1.3],\n",
            "       [6.6, 3. , 4.4, 1.4],\n",
            "       [6.8, 2.8, 4.8, 1.4],\n",
            "       [6.7, 3. , 5. , 1.7],\n",
            "       [6. , 2.9, 4.5, 1.5],\n",
            "       [5.7, 2.6, 3.5, 1. ],\n",
            "       [5.5, 2.4, 3.8, 1.1],\n",
            "       [5.5, 2.4, 3.7, 1. ],\n",
            "       [5.8, 2.7, 3.9, 1.2],\n",
            "       [6. , 2.7, 5.1, 1.6],\n",
            "       [5.4, 3. , 4.5, 1.5],\n",
            "       [6. , 3.4, 4.5, 1.6],\n",
            "       [6.7, 3.1, 4.7, 1.5],\n",
            "       [6.3, 2.3, 4.4, 1.3],\n",
            "       [5.6, 3. , 4.1, 1.3],\n",
            "       [5.5, 2.5, 4. , 1.3],\n",
            "       [5.5, 2.6, 4.4, 1.2],\n",
            "       [6.1, 3. , 4.6, 1.4],\n",
            "       [5.8, 2.6, 4. , 1.2],\n",
            "       [5. , 2.3, 3.3, 1. ],\n",
            "       [5.6, 2.7, 4.2, 1.3],\n",
            "       [5.7, 3. , 4.2, 1.2],\n",
            "       [5.7, 2.9, 4.2, 1.3],\n",
            "       [6.2, 2.9, 4.3, 1.3],\n",
            "       [5.1, 2.5, 3. , 1.1],\n",
            "       [5.7, 2.8, 4.1, 1.3],\n",
            "       [6.3, 3.3, 6. , 2.5],\n",
            "       [5.8, 2.7, 5.1, 1.9],\n",
            "       [7.1, 3. , 5.9, 2.1],\n",
            "       [6.3, 2.9, 5.6, 1.8],\n",
            "       [6.5, 3. , 5.8, 2.2],\n",
            "       [7.6, 3. , 6.6, 2.1],\n",
            "       [4.9, 2.5, 4.5, 1.7],\n",
            "       [7.3, 2.9, 6.3, 1.8],\n",
            "       [6.7, 2.5, 5.8, 1.8],\n",
            "       [7.2, 3.6, 6.1, 2.5],\n",
            "       [6.5, 3.2, 5.1, 2. ],\n",
            "       [6.4, 2.7, 5.3, 1.9],\n",
            "       [6.8, 3. , 5.5, 2.1],\n",
            "       [5.7, 2.5, 5. , 2. ],\n",
            "       [5.8, 2.8, 5.1, 2.4],\n",
            "       [6.4, 3.2, 5.3, 2.3],\n",
            "       [6.5, 3. , 5.5, 1.8],\n",
            "       [7.7, 3.8, 6.7, 2.2],\n",
            "       [7.7, 2.6, 6.9, 2.3],\n",
            "       [6. , 2.2, 5. , 1.5],\n",
            "       [6.9, 3.2, 5.7, 2.3],\n",
            "       [5.6, 2.8, 4.9, 2. ],\n",
            "       [7.7, 2.8, 6.7, 2. ],\n",
            "       [6.3, 2.7, 4.9, 1.8],\n",
            "       [6.7, 3.3, 5.7, 2.1],\n",
            "       [7.2, 3.2, 6. , 1.8],\n",
            "       [6.2, 2.8, 4.8, 1.8],\n",
            "       [6.1, 3. , 4.9, 1.8],\n",
            "       [6.4, 2.8, 5.6, 2.1],\n",
            "       [7.2, 3. , 5.8, 1.6],\n",
            "       [7.4, 2.8, 6.1, 1.9],\n",
            "       [7.9, 3.8, 6.4, 2. ],\n",
            "       [6.4, 2.8, 5.6, 2.2],\n",
            "       [6.3, 2.8, 5.1, 1.5],\n",
            "       [6.1, 2.6, 5.6, 1.4],\n",
            "       [7.7, 3. , 6.1, 2.3],\n",
            "       [6.3, 3.4, 5.6, 2.4],\n",
            "       [6.4, 3.1, 5.5, 1.8],\n",
            "       [6. , 3. , 4.8, 1.8],\n",
            "       [6.9, 3.1, 5.4, 2.1],\n",
            "       [6.7, 3.1, 5.6, 2.4],\n",
            "       [6.9, 3.1, 5.1, 2.3],\n",
            "       [5.8, 2.7, 5.1, 1.9],\n",
            "       [6.8, 3.2, 5.9, 2.3],\n",
            "       [6.7, 3.3, 5.7, 2.5],\n",
            "       [6.7, 3. , 5.2, 2.3],\n",
            "       [6.3, 2.5, 5. , 1.9],\n",
            "       [6.5, 3. , 5.2, 2. ],\n",
            "       [6.2, 3.4, 5.4, 2.3],\n",
            "       [5.9, 3. , 5.1, 1.8]]), array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=int64))]\n",
            "Class 0 has 50 instances after oversampling\n",
            "Class 1 has 199 instances after oversampling\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[None, None]"
            ]
          },
          "execution_count": 62,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "unique_classes, counts = np.unique(y, return_counts=True)\n",
        "print(dict(zip(unique_classes, counts)))\n",
        "\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "# Calcul des instances par classe\n",
        "class_counts = dict(zip(*np.unique(y, return_counts=True)))\n",
        "\n",
        "# Affichage du nombre d'instances par classe\n",
        "for label, count in class_counts.items():\n",
        "    print('Class {} has {} instances'.format(label, count))\n",
        "\n",
        "# Création et utilisation de FCM_smote\n",
        "FCM_smote = FCMCENTERSMOTE(\n",
        "    kmeans_args={'n_clusters': num_clusters},\n",
        "    smote_args={'k_neighbors': 2},\n",
        "    imbalance_ratio_threshold=1,\n",
        "    density_power=4\n",
        ")\n",
        "X_resampled, y_resampled = FCM_smote.fit_resample(X, y)\n",
        "\n",
        "[print('Class {} has {} instances after oversampling'.format(label, count))\n",
        " for label, count in zip(*np.unique(y_resampled, return_counts=True))]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.1, random_state=42)\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialiser le classificateur k-NN avec k=3\n",
        "knn = KNeighborsClassifier(n_neighbors=3)\n",
        "\n",
        "# Entraîner le modèle\n",
        "knn.fit(X_train, y_train)\n",
        "\n",
        "# Prédire les étiquettes sur l'ensemble de test\n",
        "y_pred = knn.predict(X_test)\n",
        "\n",
        "from sklearn import svm\n",
        "clf = svm.SVC(kernel='linear')\n",
        "clf.fit(X_train, y_train)\n",
        "y_pred = clf.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[44 91]\n",
            "recall 1.0\n",
            "specificity_val 1.0\n",
            "Precision: 1.0\n",
            "Recall: 1.0\n",
            "G-M 1.0\n",
            "Accuracy: 1.0\n",
            "F1-score: 1.0\n",
            "AUC: 1.0\n",
            "[[6 0]\n",
            " [0 9]]\n"
          ]
        }
      ],
      "source": [
        "from sklearn import metrics\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import recall_score, accuracy_score, confusion_matrix\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "X = df.iloc[:,0:4].to_numpy()\n",
        "y=df.iloc[:,4].to_numpy()\n",
        "df['test']=y\n",
        "df['test'] = df['test'].replace('Iris-setosa', 0)\n",
        "df['test'] = df['test'].replace('Iris-virginica', 1)\n",
        "df['test'] = df['test'].replace('Iris-versicolor', 0)\n",
        "#df['test'] = df['test'].replace(' pp', 0)\n",
        "y=df['test'].to_numpy()\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.1, random_state=90)\n",
        "\n",
        "\n",
        "# Calcul de la sensibilité (recall)\n",
        "def sensitivity(y_true, y_pred):\n",
        "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
        "    return tp / (tp + fn)\n",
        "\n",
        "# Calcul de la spécificité\n",
        "def specificity(y_true, y_pred):\n",
        "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
        "    return tn / (tn + fp)\n",
        "\n",
        "# Initialiser le classificateur k-NN avec k=3\n",
        "knn = KNeighborsClassifier(n_neighbors=3)\n",
        "\n",
        "# Entraîner le modèle\n",
        "knn.fit(X_train, y_train)\n",
        "\n",
        "# Prédire les étiquettes sur l'ensemble de test\n",
        "y_pred = knn.predict(X_test)\n",
        "\n",
        "print(np.bincount(y_train))\n",
        "\n",
        "recall = recall_score(y_test, y_pred)\n",
        "specificity_val = specificity(y_test, y_pred)\n",
        "g_mean = (recall * specificity_val) ** 0.5\n",
        "print(\"recall\",recall)\n",
        "print(\"specificity_val\",specificity_val)\n",
        "print(\"Precision:\",metrics.precision_score(y_test, y_pred))\n",
        "print(\"Recall:\",metrics.recall_score(y_test, y_pred))\n",
        "print(\"G-M\",g_mean)\n",
        "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n",
        "print(\"F1-score:\",metrics.f1_score(y_test, y_pred))\n",
        "print(\"AUC:\",metrics.roc_auc_score(y_test, y_pred))\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "     class\n",
            "0        1\n",
            "1        1\n",
            "2        1\n",
            "3        1\n",
            "4        1\n",
            "..     ...\n",
            "173      3\n",
            "174      3\n",
            "175      3\n",
            "176      3\n",
            "177      3\n",
            "\n",
            "[178 rows x 1 columns]\n"
          ]
        }
      ],
      "source": [
        "from ucimlrepo import fetch_ucirepo \n",
        "  \n",
        "# fetch dataset \n",
        "wine = fetch_ucirepo(id=109) \n",
        "  \n",
        "# data (as pandas dataframes) \n",
        "X = wine.data.features\n",
        "y = wine.data.targets \n",
        "  \n",
        "print(y)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
