{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/harshj3915/Intuitionistic-FCM-Smote/blob/Harsh/Harsh_FCM-CSMOTE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 137,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: scikit-learn in c:\\users\\91843\\documents\\vscode codes\\intuitionistic-fcm-smote\\intuitionistic-fcm-smote\\.venv\\lib\\site-packages (1.5.2)\n",
            "Requirement already satisfied: numpy>=1.19.5 in c:\\users\\91843\\documents\\vscode codes\\intuitionistic-fcm-smote\\intuitionistic-fcm-smote\\.venv\\lib\\site-packages (from scikit-learn) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\91843\\documents\\vscode codes\\intuitionistic-fcm-smote\\intuitionistic-fcm-smote\\.venv\\lib\\site-packages (from scikit-learn) (1.14.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\91843\\documents\\vscode codes\\intuitionistic-fcm-smote\\intuitionistic-fcm-smote\\.venv\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\91843\\documents\\vscode codes\\intuitionistic-fcm-smote\\intuitionistic-fcm-smote\\.venv\\lib\\site-packages (from scikit-learn) (3.5.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 24.0 -> 24.2\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "# %pip install numpy\n",
        "# %pip install -q numpy scikit-learn imbalanced-learn\n",
        "# %pip install ucimlrepo matplotlib\n",
        "# %pip install -U imbalanced-learn fcmeans\n",
        "# %pip install -U scikit-learn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 128,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'uci_id': 53, 'name': 'Iris', 'repository_url': 'https://archive.ics.uci.edu/dataset/53/iris', 'data_url': 'https://archive.ics.uci.edu/static/public/53/data.csv', 'abstract': 'A small classic dataset from Fisher, 1936. One of the earliest known datasets used for evaluating classification methods.\\n', 'area': 'Biology', 'tasks': ['Classification'], 'characteristics': ['Tabular'], 'num_instances': 150, 'num_features': 4, 'feature_types': ['Real'], 'demographics': [], 'target_col': ['class'], 'index_col': None, 'has_missing_values': 'no', 'missing_values_symbol': None, 'year_of_dataset_creation': 1936, 'last_updated': 'Tue Sep 12 2023', 'dataset_doi': '10.24432/C56C76', 'creators': ['R. A. Fisher'], 'intro_paper': {'ID': 191, 'type': 'NATIVE', 'title': 'The Iris data set: In search of the source of virginica', 'authors': 'A. Unwin, K. Kleinman', 'venue': 'Significance, 2021', 'year': 2021, 'journal': 'Significance, 2021', 'DOI': '1740-9713.01589', 'URL': 'https://www.semanticscholar.org/paper/4599862ea877863669a6a8e63a3c707a787d5d7e', 'sha': None, 'corpus': None, 'arxiv': None, 'mag': None, 'acl': None, 'pmid': None, 'pmcid': None}, 'additional_info': {'summary': 'This is one of the earliest datasets used in the literature on classification methods and widely used in statistics and machine learning.  The data set contains 3 classes of 50 instances each, where each class refers to a type of iris plant.  One class is linearly separable from the other 2; the latter are not linearly separable from each other.\\n\\nPredicted attribute: class of iris plant.\\n\\nThis is an exceedingly simple domain.\\n\\nThis data differs from the data presented in Fishers article (identified by Steve Chadwick,  spchadwick@espeedaz.net ).  The 35th sample should be: 4.9,3.1,1.5,0.2,\"Iris-setosa\" where the error is in the fourth feature. The 38th sample: 4.9,3.6,1.4,0.1,\"Iris-setosa\" where the errors are in the second and third features.  ', 'purpose': 'N/A', 'funded_by': None, 'instances_represent': 'Each instance is a plant', 'recommended_data_splits': None, 'sensitive_data': None, 'preprocessing_description': None, 'variable_info': None, 'citation': None}}\n",
            "           name     role         type demographic  \\\n",
            "0  sepal length  Feature   Continuous        None   \n",
            "1   sepal width  Feature   Continuous        None   \n",
            "2  petal length  Feature   Continuous        None   \n",
            "3   petal width  Feature   Continuous        None   \n",
            "4         class   Target  Categorical        None   \n",
            "\n",
            "                                         description units missing_values  \n",
            "0                                               None    cm             no  \n",
            "1                                               None    cm             no  \n",
            "2                                               None    cm             no  \n",
            "3                                               None    cm             no  \n",
            "4  class of iris plant: Iris Setosa, Iris Versico...  None             no  \n"
          ]
        }
      ],
      "source": [
        "from ucimlrepo import fetch_ucirepo \n",
        "  \n",
        "# fetch dataset \n",
        "iris = fetch_ucirepo(id=53) \n",
        "  \n",
        "# data (as pandas dataframes) \n",
        "X = iris.data.features \n",
        "y = iris.data.targets \n",
        "  \n",
        "# metadata \n",
        "print(iris.metadata) \n",
        "  \n",
        "# variable information \n",
        "print(iris.variables) \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 129,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.cluster import DBSCAN\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def extract_and_visualize_k_clusters_with_dbscan(X, k):\n",
        "    \"\"\"\n",
        "    Extract and visualize the first k clusters from the data using the DBSCAN algorithm.\n",
        "    \n",
        "    Args:\n",
        "    - X : Feature matrix (dataset)\n",
        "    - k : Number of clusters to extract\n",
        "    \n",
        "    Returns:\n",
        "    - k_clusters : List of the first k clusters\n",
        "    \"\"\"\n",
        "    # Apply DBSCAN to find clusters\n",
        "    dbscan = DBSCAN()\n",
        "    dbscan.fit(X)\n",
        "    \n",
        "    # Get the cluster labels assigned by DBSCAN\n",
        "    cluster_labels = dbscan.labels_\n",
        "    \n",
        "    # Identify the unique cluster labels (ignoring noise, labeled as -1)\n",
        "    unique_labels = np.unique(cluster_labels)\n",
        "    \n",
        "    # Initialize a list to store the first k clusters\n",
        "    k_clusters = []\n",
        "    \n",
        "    # Loop over unique labels and extract the first k clusters (excluding noise)\n",
        "    for label in unique_labels:\n",
        "        if label != -1 and len(k_clusters) < k:  # Ignore noise (-1) and stop when we get k clusters\n",
        "            cluster = X[cluster_labels == label]\n",
        "            k_clusters.append(cluster)\n",
        "\n",
        "    # Visualization of clusters using the first two features for 2D plotting\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    \n",
        "    # Loop over each cluster and plot\n",
        "    for label in unique_labels:\n",
        "        if label == -1:\n",
        "            # Plot noise points in black\n",
        "            plt.scatter(X[cluster_labels == label][:, 0], X[cluster_labels == label][:, 1], \n",
        "                        c='k', marker='x', label='Noise')\n",
        "        else:\n",
        "            if len(k_clusters) < k:  # Only plot up to k clusters\n",
        "                # Generate a color for the cluster\n",
        "                color = plt.cm.rainbow(float(label) / len(unique_labels))\n",
        "                plt.scatter(X[cluster_labels == label][:, 0], X[cluster_labels == label][:, 1], \n",
        "                            c=[color], label=f'Cluster {label}')\n",
        "    \n",
        "    # Add labels and title to the plot\n",
        "    plt.title(f'DBSCAN Clustering with First {k} Clusters')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "    \n",
        "    return k_clusters\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 130,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[array([[5.1, 3.5, 1.4, 0.2],\n",
            "       [4.9, 3. , 1.4, 0.2],\n",
            "       [4.7, 3.2, 1.3, 0.2],\n",
            "       [4.6, 3.1, 1.5, 0.2],\n",
            "       [5. , 3.6, 1.4, 0.2],\n",
            "       [5.4, 3.9, 1.7, 0.4],\n",
            "       [4.6, 3.4, 1.4, 0.3],\n",
            "       [5. , 3.4, 1.5, 0.2],\n",
            "       [4.4, 2.9, 1.4, 0.2],\n",
            "       [4.9, 3.1, 1.5, 0.1],\n",
            "       [5.4, 3.7, 1.5, 0.2],\n",
            "       [4.8, 3.4, 1.6, 0.2],\n",
            "       [4.8, 3. , 1.4, 0.1],\n",
            "       [4.3, 3. , 1.1, 0.1],\n",
            "       [5.8, 4. , 1.2, 0.2],\n",
            "       [5.7, 4.4, 1.5, 0.4],\n",
            "       [5.4, 3.9, 1.3, 0.4],\n",
            "       [5.1, 3.5, 1.4, 0.3],\n",
            "       [5.7, 3.8, 1.7, 0.3],\n",
            "       [5.1, 3.8, 1.5, 0.3],\n",
            "       [5.4, 3.4, 1.7, 0.2],\n",
            "       [5.1, 3.7, 1.5, 0.4],\n",
            "       [4.6, 3.6, 1. , 0.2],\n",
            "       [5.1, 3.3, 1.7, 0.5],\n",
            "       [4.8, 3.4, 1.9, 0.2],\n",
            "       [5. , 3. , 1.6, 0.2],\n",
            "       [5. , 3.4, 1.6, 0.4],\n",
            "       [5.2, 3.5, 1.5, 0.2],\n",
            "       [5.2, 3.4, 1.4, 0.2],\n",
            "       [4.7, 3.2, 1.6, 0.2],\n",
            "       [4.8, 3.1, 1.6, 0.2],\n",
            "       [5.4, 3.4, 1.5, 0.4],\n",
            "       [5.2, 4.1, 1.5, 0.1],\n",
            "       [5.5, 4.2, 1.4, 0.2],\n",
            "       [4.9, 3.1, 1.5, 0.1],\n",
            "       [5. , 3.2, 1.2, 0.2],\n",
            "       [5.5, 3.5, 1.3, 0.2],\n",
            "       [4.9, 3.1, 1.5, 0.1],\n",
            "       [4.4, 3. , 1.3, 0.2],\n",
            "       [5.1, 3.4, 1.5, 0.2],\n",
            "       [5. , 3.5, 1.3, 0.3],\n",
            "       [4.4, 3.2, 1.3, 0.2],\n",
            "       [5. , 3.5, 1.6, 0.6],\n",
            "       [5.1, 3.8, 1.9, 0.4],\n",
            "       [4.8, 3. , 1.4, 0.3],\n",
            "       [5.1, 3.8, 1.6, 0.2],\n",
            "       [4.6, 3.2, 1.4, 0.2],\n",
            "       [5.3, 3.7, 1.5, 0.2],\n",
            "       [5. , 3.3, 1.4, 0.2]]), array([[7. , 3.2, 4.7, 1.4],\n",
            "       [6.4, 3.2, 4.5, 1.5],\n",
            "       [6.9, 3.1, 4.9, 1.5],\n",
            "       [5.5, 2.3, 4. , 1.3],\n",
            "       [6.5, 2.8, 4.6, 1.5],\n",
            "       [5.7, 2.8, 4.5, 1.3],\n",
            "       [6.3, 3.3, 4.7, 1.6],\n",
            "       [6.6, 2.9, 4.6, 1.3],\n",
            "       [5.2, 2.7, 3.9, 1.4],\n",
            "       [5.9, 3. , 4.2, 1.5],\n",
            "       [6. , 2.2, 4. , 1. ],\n",
            "       [6.1, 2.9, 4.7, 1.4],\n",
            "       [5.6, 2.9, 3.6, 1.3],\n",
            "       [6.7, 3.1, 4.4, 1.4],\n",
            "       [5.6, 3. , 4.5, 1.5],\n",
            "       [5.8, 2.7, 4.1, 1. ],\n",
            "       [5.6, 2.5, 3.9, 1.1],\n",
            "       [5.9, 3.2, 4.8, 1.8],\n",
            "       [6.1, 2.8, 4. , 1.3],\n",
            "       [6.3, 2.5, 4.9, 1.5],\n",
            "       [6.1, 2.8, 4.7, 1.2],\n",
            "       [6.4, 2.9, 4.3, 1.3],\n",
            "       [6.6, 3. , 4.4, 1.4],\n",
            "       [6.8, 2.8, 4.8, 1.4],\n",
            "       [6.7, 3. , 5. , 1.7],\n",
            "       [6. , 2.9, 4.5, 1.5],\n",
            "       [5.7, 2.6, 3.5, 1. ],\n",
            "       [5.5, 2.4, 3.8, 1.1],\n",
            "       [5.5, 2.4, 3.7, 1. ],\n",
            "       [5.8, 2.7, 3.9, 1.2],\n",
            "       [6. , 2.7, 5.1, 1.6],\n",
            "       [5.4, 3. , 4.5, 1.5],\n",
            "       [6. , 3.4, 4.5, 1.6],\n",
            "       [6.7, 3.1, 4.7, 1.5],\n",
            "       [5.6, 3. , 4.1, 1.3],\n",
            "       [5.5, 2.5, 4. , 1.3],\n",
            "       [5.5, 2.6, 4.4, 1.2],\n",
            "       [6.1, 3. , 4.6, 1.4],\n",
            "       [5.8, 2.6, 4. , 1.2],\n",
            "       [5.6, 2.7, 4.2, 1.3],\n",
            "       [5.7, 3. , 4.2, 1.2],\n",
            "       [5.7, 2.9, 4.2, 1.3],\n",
            "       [6.2, 2.9, 4.3, 1.3],\n",
            "       [5.7, 2.8, 4.1, 1.3],\n",
            "       [6.3, 3.3, 6. , 2.5],\n",
            "       [5.8, 2.7, 5.1, 1.9],\n",
            "       [7.1, 3. , 5.9, 2.1],\n",
            "       [6.3, 2.9, 5.6, 1.8],\n",
            "       [6.5, 3. , 5.8, 2.2],\n",
            "       [7.3, 2.9, 6.3, 1.8],\n",
            "       [6.5, 3.2, 5.1, 2. ],\n",
            "       [6.4, 2.7, 5.3, 1.9],\n",
            "       [6.8, 3. , 5.5, 2.1],\n",
            "       [5.7, 2.5, 5. , 2. ],\n",
            "       [5.8, 2.8, 5.1, 2.4],\n",
            "       [6.4, 3.2, 5.3, 2.3],\n",
            "       [6.5, 3. , 5.5, 1.8],\n",
            "       [6. , 2.2, 5. , 1.5],\n",
            "       [6.9, 3.2, 5.7, 2.3],\n",
            "       [5.6, 2.8, 4.9, 2. ],\n",
            "       [6.3, 2.7, 4.9, 1.8],\n",
            "       [6.7, 3.3, 5.7, 2.1],\n",
            "       [7.2, 3.2, 6. , 1.8],\n",
            "       [6.2, 2.8, 4.8, 1.8],\n",
            "       [6.1, 3. , 4.9, 1.8],\n",
            "       [6.4, 2.8, 5.6, 2.1],\n",
            "       [7.2, 3. , 5.8, 1.6],\n",
            "       [7.4, 2.8, 6.1, 1.9],\n",
            "       [6.4, 2.8, 5.6, 2.2],\n",
            "       [6.3, 2.8, 5.1, 1.5],\n",
            "       [6.3, 3.4, 5.6, 2.4],\n",
            "       [6.4, 3.1, 5.5, 1.8],\n",
            "       [6. , 3. , 4.8, 1.8],\n",
            "       [6.9, 3.1, 5.4, 2.1],\n",
            "       [6.7, 3.1, 5.6, 2.4],\n",
            "       [6.9, 3.1, 5.1, 2.3],\n",
            "       [5.8, 2.7, 5.1, 1.9],\n",
            "       [6.8, 3.2, 5.9, 2.3],\n",
            "       [6.7, 3.3, 5.7, 2.5],\n",
            "       [6.7, 3. , 5.2, 2.3],\n",
            "       [6.3, 2.5, 5. , 1.9],\n",
            "       [6.5, 3. , 5.2, 2. ],\n",
            "       [6.2, 3.4, 5.4, 2.3],\n",
            "       [5.9, 3. , 5.1, 1.8]])]\n"
          ]
        }
      ],
      "source": [
        "from ucimlrepo import fetch_ucirepo \n",
        "  \n",
        "# fetch dataset \n",
        "iris = fetch_ucirepo(id=53) \n",
        "  \n",
        "# data (as pandas dataframes) \n",
        "X = iris.data.features.values\n",
        "\n",
        "  \n",
        "print(extract_and_visualize_k_clusters_with_dbscan(X, 10))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 131,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics.pairwise import euclidean_distances\n",
        "from fcmeans import FCM\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "import copy\n",
        "import warnings\n",
        "import math\n",
        "import copy\n",
        "import numpy as np\n",
        "from sklearn.mixture import GaussianMixture\n",
        "from sklearn.utils import check_random_state\n",
        "from sklearn.metrics.pairwise import euclidean_distances\n",
        "from imblearn.over_sampling.base import BaseOverSampler\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "from imblearn.exceptions import raise_isinstance_error\n",
        "from imblearn.utils import check_neighbors_object\n",
        "from imblearn.utils.deprecation import deprecate_parameter\n",
        "class FCMCENTERSMOTE(BaseOverSampler):\n",
        "    def __init__(self, sampling_strategy='auto', random_state=None, kmeans_args=None, smote_args=None,\n",
        "                 imbalance_ratio_threshold=1.0, density_power=None, use_minibatch_kmeans=True, n_jobs=1, **kwargs):\n",
        "        super(FCMCENTERSMOTE, self).__init__(sampling_strategy=sampling_strategy, **kwargs)\n",
        "        if kmeans_args is None:\n",
        "            kmeans_args = {}\n",
        "        if smote_args is None:\n",
        "            smote_args = {}\n",
        "        self.imbalance_ratio_threshold = imbalance_ratio_threshold\n",
        "        self.kmeans_args = copy.deepcopy(kmeans_args)\n",
        "        self.smote_args = copy.deepcopy(smote_args)\n",
        "        self.random_state = random_state\n",
        "        self.n_jobs = n_jobs\n",
        "        self.use_minibatch_kmeans = use_minibatch_kmeans\n",
        "        self.density_power = density_power\n",
        "\n",
        "    def _cluster(self, X):\n",
        "        fcm = FCM(**self.kmeans_args)\n",
        "        fcm.fit(X)\n",
        "        fcm_labels = fcm.predict(X)\n",
        "        cluster_assignment = np.asarray(fcm_labels)\n",
        "        print(\"cluster_assignment\",cluster_assignment)\n",
        "        return cluster_assignment\n",
        "\n",
        "    def _filter_clusters(self, X, y, cluster_assignment, minority_class_label):\n",
        "      largest_cluster_label = np.max(np.unique(cluster_assignment))\n",
        "      sparsity_factors = np.zeros((largest_cluster_label + 1,), dtype=np.float64)\n",
        "      minority_mask = (y == minority_class_label)\n",
        "      imbalance_ratio_threshold = self.imbalance_ratio_threshold\n",
        "      \n",
        "\n",
        "      if isinstance(imbalance_ratio_threshold, dict):\n",
        "          imbalance_ratio_threshold = imbalance_ratio_threshold.get(minority_class_label, 1.0)\n",
        "\n",
        "      for i in np.unique(cluster_assignment):\n",
        "          cluster = X[cluster_assignment == i]\n",
        "          mask = minority_mask[cluster_assignment == i]\n",
        "          minority_count = np.sum(mask)\n",
        "          majority_count = np.sum(~mask)\n",
        "          imbalance_ratio = (majority_count + 1) / (minority_count + 1)\n",
        "\n",
        "          if (imbalance_ratio < imbalance_ratio_threshold) and (minority_count > 1):\n",
        "              distances = euclidean_distances(cluster[mask])\n",
        "              non_diagonal_distances = distances[~np.eye(distances.shape[0], dtype=bool)]\n",
        "              average_minority_distance = np.mean(non_diagonal_distances) if non_diagonal_distances.size > 0 else 0.0\n",
        "\n",
        "              if average_minority_distance == 0:\n",
        "                  average_minority_distance = 1e-1\n",
        "\n",
        "              density_factor = minority_count / (average_minority_distance ** self.density_power)\n",
        "              sparsity_factors[i] = 1 / density_factor\n",
        "\n",
        "      sparsity_sum = np.sum(sparsity_factors)\n",
        "      if sparsity_sum == 0:\n",
        "          sparsity_sum = 1\n",
        "\n",
        "      sampling_weights = sparsity_factors / sparsity_sum if sparsity_sum != 0 else np.full(sparsity_factors.shape, 1.0)\n",
        "\n",
        "      return sampling_weights\n",
        "    @staticmethod\n",
        "    def smote_oversample_with_point_value(X, y, point_index, sampling_ratio=1.0,smote_args= None,k=5):\n",
        "      if smote_args is not None and 'k_neighbors' in smote_args:\n",
        "            k = smote_args['k_neighbors']\n",
        "      minority_class = np.unique(y)[np.argmin(np.bincount(y))]\n",
        "      minority_indices = np.where(y == minority_class)[0]\n",
        "      print(point_index)\n",
        "      print(\"hehe \", isinstance(point_index, int) and point_index < len(y) and y[point_index] == minority_class)\n",
        "      \n",
        "\n",
        "\n",
        "      if isinstance(point_index, int) and point_index < len(y) and y[point_index] == minority_class:\n",
        "        num_minority_samples = len(minority_indices)\n",
        "        num_majority_samples = int(sampling_ratio * len(y)) - num_minority_samples\n",
        "\n",
        "        knn = NearestNeighbors(n_neighbors=k + 1)\n",
        "        knn.fit(X[minority_indices])\n",
        "        nn_indices = knn.kneighbors([X[point_index]], return_distance=False)[0][1:]\n",
        "\n",
        "        synthetic_samples = []\n",
        "        for i in range(num_minority_samples):\n",
        "            nn_index = np.random.choice(nn_indices)\n",
        "            diff = X[nn_index] - X[point_index]\n",
        "            synthetic_sample = X[point_index] + np.random.rand() * diff\n",
        "            synthetic_samples.append(synthetic_sample)\n",
        "        synthetic_samples = np.array(synthetic_samples)\n",
        "\n",
        "        X_resampled = np.vstack((X, synthetic_samples))\n",
        "        y_resampled = np.hstack((y, np.full(len(synthetic_samples), minority_class)))\n",
        "\n",
        "        shuffle_indices = np.random.permutation(len(X_resampled))\n",
        "        X_resampled = X_resampled[shuffle_indices]\n",
        "        y_resampled = y_resampled[shuffle_indices]\n",
        "\n",
        "        return X_resampled, y_resampled\n",
        "      else:\n",
        "        return X, y\n",
        "\n",
        "    def _fit_resample(self, X, y):\n",
        "        \"\"\"Resample the dataset.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        X : ndarray, shape (n_samples, n_features)\n",
        "            Matrix containing the data which have to be sampled.\n",
        "\n",
        "        y : ndarray, shape (n_samples, )\n",
        "            Corresponding label for each sample in X.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        X_resampled : ndarray, shape (n_samples_new, n_features)\n",
        "            The array containing the resampled data.\n",
        "\n",
        "        y_resampled : ndarray, shape (n_samples_new)\n",
        "            The corresponding labels of ``X_resampled``\n",
        "\n",
        "        \"\"\"\n",
        "        self._set_subalgorithm_params()\n",
        "\n",
        "        if self.density_power is None:\n",
        "            self.density_power = X.shape[1]\n",
        "\n",
        "        resampled = [ (X.copy(), y.copy()) ]\n",
        "        sampling_ratio = {k: v for k, v in self.sampling_strategy_.items()}\n",
        "        # sampling_strategy_ does not contain classes where n_samples 0\n",
        "        for class_label in np.unique(y):\n",
        "            if class_label not in sampling_ratio:\n",
        "                sampling_ratio[class_label] = 0\n",
        "        print(\"sampling_ratio\",sampling_ratio)\n",
        "        for minority_class_label, n_samples in sampling_ratio.items():\n",
        "            print(\"minority_class_label\",minority_class_label)\n",
        "            if n_samples == 0:\n",
        "                continue\n",
        "\n",
        "            cluster_assignment = self._cluster(X)\n",
        "            sampling_weights = self._filter_clusters(X, y, cluster_assignment, minority_class_label)\n",
        "            print('Sampling Weights : ',sampling_weights)\n",
        "            smote_args = self.smote_args.copy()\n",
        "            if np.count_nonzero(sampling_weights) > 0:\n",
        "                # perform k-means smote\n",
        "                for i in np.unique(cluster_assignment):\n",
        "                    \n",
        "                    cluster_X = X[cluster_assignment == i]\n",
        "                    cluster_y = y[cluster_assignment == i]\n",
        "                    if sampling_weights[i] > 0:\n",
        "                        # determine ratio for oversampling the current cluster\n",
        "                        target_ratio = {label: np.count_nonzero(cluster_y == label) for label in sampling_ratio}\n",
        "                        cluster_minority_count = np.count_nonzero(cluster_y == minority_class_label)\n",
        "                        generate_count = int(round(n_samples * sampling_weights[i]))\n",
        "                        target_ratio[minority_class_label] = generate_count + cluster_minority_count\n",
        "\n",
        "                        # make sure that cluster_y has more than 1 class, adding a random point otherwise\n",
        "                        remove_index = -1\n",
        "                        if np.unique(cluster_y).size < 2:\n",
        "                            remove_index = cluster_y.size\n",
        "                            cluster_X = np.append(cluster_X, np.zeros((1,cluster_X.shape[1])), axis=0)\n",
        "                            majority_class_label = next( key for key in sampling_ratio.keys() if key != minority_class_label )\n",
        "                            target_ratio[majority_class_label] = 1 + target_ratio[majority_class_label]\n",
        "                            cluster_y = np.append(cluster_y, np.asarray(majority_class_label).reshape((1,)), axis=0)\n",
        "                        \n",
        "                        # clear target ratio of labels not present in cluster\n",
        "                        for label in list(target_ratio.keys()):\n",
        "                            if label not in cluster_y:\n",
        "                                del target_ratio[label]\n",
        "                        \n",
        "                        # modify copy of the user defined smote_args to reflect computed parameters\n",
        "                        smote_args['sampling_strategy'] = target_ratio\n",
        "                        \n",
        "                        \n",
        "                        smote_args = self._validate_smote_args(smote_args, cluster_minority_count)\n",
        "                        # Get the center of the cluster to use as the point for SMOTE oversampling\n",
        "                        cluster_center = np.mean(cluster_X, axis=0)\n",
        "                        k_value = smote_args['k_neighbors']\n",
        "                        print(\"cluster_center\",cluster_center)\n",
        "                        print('k_value',k_value)\n",
        "                        print(\"i\",i)\n",
        "                        X_resampled_cluster, y_resampled_cluster = self.smote_oversample_with_point_value(\n",
        "                            X, y, cluster_center, sampling_ratio=n_samples / X.shape[0],\n",
        "                            k=k_value)\n",
        "                        print(\"After \",X_resampled_cluster)\n",
        "                        \n",
        "                        # if k_neighbors is 0, perform random oversampling instead of smote\n",
        "                        if 'k_neighbors' in smote_args and smote_args['k_neighbors'] == 0:\n",
        "                                oversampler_args = {}\n",
        "                                if 'random_state' in smote_args:\n",
        "                                    oversampler_args['random_state'] = smote_args['random_state']\n",
        "                                oversampler = RandomOverSampler(**oversampler_args)\n",
        "                        print(\"line 1\")\n",
        "                        # finally, apply smote to cluster\n",
        "                        with warnings.catch_warnings():\n",
        "                            # ignore warnings about minority class getting bigger than majority class\n",
        "                            # since this would only be true within this cluster\n",
        "                            warnings.filterwarnings(action='ignore', category=UserWarning, message=r'After over-sampling, the number of samples \\(.*\\) in class .* will be larger than the number of samples in the majority class \\(class #.* \\-\\> .*\\)')\n",
        "                            cluster_resampled_X, cluster_resampled_y = self.smote_oversample_with_point_value(\n",
        "                            X, y, cluster_center, sampling_ratio=n_samples / X.shape[0],\n",
        "                            k=smote_args['k_neighbors'])\n",
        "                        print(\"line 2\")\n",
        "                        if remove_index > -1:\n",
        "                            # since SMOTE's results are ordered the same way as the data passed into it,\n",
        "                            # the temporarily added point is at the same index position as it was added.\n",
        "                            for l in [cluster_resampled_X, cluster_resampled_y, cluster_X, cluster_y]:\n",
        "                                np.delete(l, remove_index, 0)\n",
        "\n",
        "                        # add new generated samples to resampled\n",
        "                        print(resampled[-2:])\n",
        "                        resampled.append( (\n",
        "                            cluster_resampled_X[cluster_y.size:,:],\n",
        "                            cluster_resampled_y[cluster_y.size:]))\n",
        "                        print(resampled[-2:])\n",
        "                        \n",
        "            else:\n",
        "                # all weights are zero -> perform regular smote\n",
        "                warnings.warn('No minority clusters found for class {}. Performing regular SMOTE. Try changing the number of clusters.'.format(minority_class_label))\n",
        "                target_ratio = {label: np.count_nonzero(y == label) for label in sampling_ratio}\n",
        "                target_ratio[minority_class_label] = sampling_ratio[minority_class_label]\n",
        "                minority_count = np.count_nonzero(y == minority_class_label)\n",
        "                smote_args = self._validate_smote_args(smote_args, minority_count)\n",
        "                # Get the center of the cluster to use as the point for SMOTE oversampling\n",
        "                cluster_center = np.mean(cluster_X, axis=0)\n",
        "                X_resampled_cluster, y_resampled_cluster = self.smote_oversample_with_point_value(\n",
        "                    X, y, cluster_center, sampling_ratio=n_samples / X.shape[0],\n",
        "                            k=smote_args['k_neighbors'])\n",
        "\n",
        "        print(\"resampled\",resampled)\n",
        "        resampled = list(zip(*resampled))\n",
        "        if(len(resampled) > 0):\n",
        "            X_resampled = np.concatenate(resampled[0], axis=0)\n",
        "            y_resampled = np.concatenate(resampled[1], axis=0)\n",
        "        return X_resampled, y_resampled\n",
        "\n",
        "    def _validate_smote_args(self, smote_args, minority_count):\n",
        "      max_k_neighbors = minority_count - 1\n",
        "      if 'k' in smote_args and smote_args['k'] > max_k_neighbors:\n",
        "          smote_args['k'] = max_k_neighbors\n",
        "      return smote_args\n",
        "\n",
        "    def _set_subalgorithm_params(self):\n",
        "      if self.random_state is not None:\n",
        "          if 'random_state' not in self.smote_args:\n",
        "              self.smote_args['random_state'] = self.random_state\n",
        "          if 'random_state' not in self.kmeans_args:\n",
        "              self.kmeans_args['random_state'] = self.random_state\n",
        "\n",
        "      if self.n_jobs is not None:\n",
        "          if 'n_jobs' not in self.smote_args:\n",
        "              self.smote_args['n_jobs'] = self.n_jobs\n",
        "          if 'n_jobs' not in self.kmeans_args:\n",
        "              if not self.use_minibatch_kmeans:\n",
        "                  self.kmeans_args['n_jobs'] = self.n_jobs\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 132,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of occurrences of -1 in the 'Class' column: 0\n",
            "Distinct classes: [0 1]\n",
            "{'uci_id': 53, 'name': 'Iris', 'repository_url': 'https://archive.ics.uci.edu/dataset/53/iris', 'data_url': 'https://archive.ics.uci.edu/static/public/53/data.csv', 'abstract': 'A small classic dataset from Fisher, 1936. One of the earliest known datasets used for evaluating classification methods.\\n', 'area': 'Biology', 'tasks': ['Classification'], 'characteristics': ['Tabular'], 'num_instances': 150, 'num_features': 4, 'feature_types': ['Real'], 'demographics': [], 'target_col': ['class'], 'index_col': None, 'has_missing_values': 'no', 'missing_values_symbol': None, 'year_of_dataset_creation': 1936, 'last_updated': 'Tue Sep 12 2023', 'dataset_doi': '10.24432/C56C76', 'creators': ['R. A. Fisher'], 'intro_paper': {'ID': 191, 'type': 'NATIVE', 'title': 'The Iris data set: In search of the source of virginica', 'authors': 'A. Unwin, K. Kleinman', 'venue': 'Significance, 2021', 'year': 2021, 'journal': 'Significance, 2021', 'DOI': '1740-9713.01589', 'URL': 'https://www.semanticscholar.org/paper/4599862ea877863669a6a8e63a3c707a787d5d7e', 'sha': None, 'corpus': None, 'arxiv': None, 'mag': None, 'acl': None, 'pmid': None, 'pmcid': None}, 'additional_info': {'summary': 'This is one of the earliest datasets used in the literature on classification methods and widely used in statistics and machine learning.  The data set contains 3 classes of 50 instances each, where each class refers to a type of iris plant.  One class is linearly separable from the other 2; the latter are not linearly separable from each other.\\n\\nPredicted attribute: class of iris plant.\\n\\nThis is an exceedingly simple domain.\\n\\nThis data differs from the data presented in Fishers article (identified by Steve Chadwick,  spchadwick@espeedaz.net ).  The 35th sample should be: 4.9,3.1,1.5,0.2,\"Iris-setosa\" where the error is in the fourth feature. The 38th sample: 4.9,3.6,1.4,0.1,\"Iris-setosa\" where the errors are in the second and third features.  ', 'purpose': 'N/A', 'funded_by': None, 'instances_represent': 'Each instance is a plant', 'recommended_data_splits': None, 'sensitive_data': None, 'preprocessing_description': None, 'variable_info': None, 'citation': None}}\n",
            "           name     role         type demographic  \\\n",
            "0  sepal length  Feature   Continuous        None   \n",
            "1   sepal width  Feature   Continuous        None   \n",
            "2  petal length  Feature   Continuous        None   \n",
            "3   petal width  Feature   Continuous        None   \n",
            "4         class   Target  Categorical        None   \n",
            "\n",
            "                                         description units missing_values  \n",
            "0                                               None    cm             no  \n",
            "1                                               None    cm             no  \n",
            "2                                               None    cm             no  \n",
            "3                                               None    cm             no  \n",
            "4  class of iris plant: Iris Setosa, Iris Versico...  None             no  \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\91843\\AppData\\Local\\Temp\\ipykernel_2236\\2426638330.py:18: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  df['Class'] = df['Class'].replace('Iris-virginica', 1)   # Set class 2 to 1\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from ucimlrepo import fetch_ucirepo \n",
        "\n",
        "# Fetch the Iris dataset\n",
        "iris = fetch_ucirepo(id=53)\n",
        "\n",
        "\n",
        "# Data (as pandas DataFrames)\n",
        "df = pd.DataFrame(iris.data.features)\n",
        "\n",
        "df['Class'] = iris.data.targets\n",
        "\n",
        "\n",
        "# Replace target class labels (if needed)\n",
        "# Assuming you want to convert target classes to -1 and 1, you can customize this based on your requirements\n",
        "df['Class'] = df['Class'].replace('Iris-setosa', 0)  # Set class 0 to -1\n",
        "df['Class'] = df['Class'].replace('Iris-versicolor', 1)   # Keep class 1 as 1\n",
        "df['Class'] = df['Class'].replace('Iris-virginica', 1)   # Set class 2 to 1\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Features and target arrays\n",
        "X = df.iloc[:, :-1].to_numpy()  # All columns except the last one\n",
        "y = df['Class'].to_numpy()       # The last column as target\n",
        "\n",
        "\n",
        "# Count occurrences of -1 in the target variable\n",
        "count_of_minus_one = (y == -1).sum()\n",
        "print(\"Number of occurrences of -1 in the 'Class' column:\", count_of_minus_one)\n",
        "\n",
        "# Save the DataFrame to a CSV file\n",
        "df.to_csv('iris_dataset.csv', index=False)\n",
        "\n",
        "# Get unique classes\n",
        "unique_classes = df['Class'].unique()\n",
        "print(\"Distinct classes:\", unique_classes)\n",
        "\n",
        "# Display metadata and variable information\n",
        "print(iris.metadata)\n",
        "print(iris.variables)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 133,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Class 0 has 50 instances\n",
            "Class 1 has 100 instances\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "class_counts = dict(zip(*np.unique(y, return_counts=True)))\n",
        "\n",
        "for label, count in class_counts.items():\n",
        "    print('Class {} has {} instances'.format(label, count))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 134,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of clusters found by DBSCAN: 3\n"
          ]
        }
      ],
      "source": [
        "from sklearn.cluster import DBSCAN\n",
        "import numpy as np\n",
        "\n",
        "# Assuming 'X' contains your data\n",
        "\n",
        "# Instantiating DBSCAN\n",
        "dbscan = DBSCAN(eps=0.2, min_samples=4)  # You may need to adjust eps and min_samples\n",
        "\n",
        "# Fitting DBSCAN to your data\n",
        "clusters = dbscan.fit_predict(X)\n",
        "\n",
        "# Getting unique cluster labels (excluding noise, labeled as -1)\n",
        "unique_labels = np.unique(clusters)\n",
        "num_clusters = len(unique_labels[unique_labels != 0])\n",
        "\n",
        "print(f\"Number of clusters found by DBSCAN: {num_clusters}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 135,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{0: 50, 1: 100}\n",
            "Class 0 has 50 instances\n",
            "Class 1 has 100 instances\n",
            "sampling_ratio {0: 50, 1: 0}\n",
            "minority_class_label 0\n",
            "cluster_assignment [2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 1 1 1 0 1 1 1 1\n",
            " 1 1 0 1 1 1 1 1 0 1 0 1 0 1 1 0 0 1 1 1 1 1 0 1 1 1 1 0 1 1 1 0 1 1 1 0 1\n",
            " 1 0]\n",
            "Sampling Weights :  [0. 0. 1.]\n",
            "cluster_center [4.90784314 3.35098039 1.43529412 0.23921569]\n",
            "k_value 2\n",
            "i 2\n",
            "[4.90784314 3.35098039 1.43529412 0.23921569]\n",
            "hehe  False\n",
            "After  [[5.1 3.5 1.4 0.2]\n",
            " [4.9 3.  1.4 0.2]\n",
            " [4.7 3.2 1.3 0.2]\n",
            " [4.6 3.1 1.5 0.2]\n",
            " [5.  3.6 1.4 0.2]\n",
            " [5.4 3.9 1.7 0.4]\n",
            " [4.6 3.4 1.4 0.3]\n",
            " [5.  3.4 1.5 0.2]\n",
            " [4.4 2.9 1.4 0.2]\n",
            " [4.9 3.1 1.5 0.1]\n",
            " [5.4 3.7 1.5 0.2]\n",
            " [4.8 3.4 1.6 0.2]\n",
            " [4.8 3.  1.4 0.1]\n",
            " [4.3 3.  1.1 0.1]\n",
            " [5.8 4.  1.2 0.2]\n",
            " [5.7 4.4 1.5 0.4]\n",
            " [5.4 3.9 1.3 0.4]\n",
            " [5.1 3.5 1.4 0.3]\n",
            " [5.7 3.8 1.7 0.3]\n",
            " [5.1 3.8 1.5 0.3]\n",
            " [5.4 3.4 1.7 0.2]\n",
            " [5.1 3.7 1.5 0.4]\n",
            " [4.6 3.6 1.  0.2]\n",
            " [5.1 3.3 1.7 0.5]\n",
            " [4.8 3.4 1.9 0.2]\n",
            " [5.  3.  1.6 0.2]\n",
            " [5.  3.4 1.6 0.4]\n",
            " [5.2 3.5 1.5 0.2]\n",
            " [5.2 3.4 1.4 0.2]\n",
            " [4.7 3.2 1.6 0.2]\n",
            " [4.8 3.1 1.6 0.2]\n",
            " [5.4 3.4 1.5 0.4]\n",
            " [5.2 4.1 1.5 0.1]\n",
            " [5.5 4.2 1.4 0.2]\n",
            " [4.9 3.1 1.5 0.1]\n",
            " [5.  3.2 1.2 0.2]\n",
            " [5.5 3.5 1.3 0.2]\n",
            " [4.9 3.1 1.5 0.1]\n",
            " [4.4 3.  1.3 0.2]\n",
            " [5.1 3.4 1.5 0.2]\n",
            " [5.  3.5 1.3 0.3]\n",
            " [4.5 2.3 1.3 0.3]\n",
            " [4.4 3.2 1.3 0.2]\n",
            " [5.  3.5 1.6 0.6]\n",
            " [5.1 3.8 1.9 0.4]\n",
            " [4.8 3.  1.4 0.3]\n",
            " [5.1 3.8 1.6 0.2]\n",
            " [4.6 3.2 1.4 0.2]\n",
            " [5.3 3.7 1.5 0.2]\n",
            " [5.  3.3 1.4 0.2]\n",
            " [7.  3.2 4.7 1.4]\n",
            " [6.4 3.2 4.5 1.5]\n",
            " [6.9 3.1 4.9 1.5]\n",
            " [5.5 2.3 4.  1.3]\n",
            " [6.5 2.8 4.6 1.5]\n",
            " [5.7 2.8 4.5 1.3]\n",
            " [6.3 3.3 4.7 1.6]\n",
            " [4.9 2.4 3.3 1. ]\n",
            " [6.6 2.9 4.6 1.3]\n",
            " [5.2 2.7 3.9 1.4]\n",
            " [5.  2.  3.5 1. ]\n",
            " [5.9 3.  4.2 1.5]\n",
            " [6.  2.2 4.  1. ]\n",
            " [6.1 2.9 4.7 1.4]\n",
            " [5.6 2.9 3.6 1.3]\n",
            " [6.7 3.1 4.4 1.4]\n",
            " [5.6 3.  4.5 1.5]\n",
            " [5.8 2.7 4.1 1. ]\n",
            " [6.2 2.2 4.5 1.5]\n",
            " [5.6 2.5 3.9 1.1]\n",
            " [5.9 3.2 4.8 1.8]\n",
            " [6.1 2.8 4.  1.3]\n",
            " [6.3 2.5 4.9 1.5]\n",
            " [6.1 2.8 4.7 1.2]\n",
            " [6.4 2.9 4.3 1.3]\n",
            " [6.6 3.  4.4 1.4]\n",
            " [6.8 2.8 4.8 1.4]\n",
            " [6.7 3.  5.  1.7]\n",
            " [6.  2.9 4.5 1.5]\n",
            " [5.7 2.6 3.5 1. ]\n",
            " [5.5 2.4 3.8 1.1]\n",
            " [5.5 2.4 3.7 1. ]\n",
            " [5.8 2.7 3.9 1.2]\n",
            " [6.  2.7 5.1 1.6]\n",
            " [5.4 3.  4.5 1.5]\n",
            " [6.  3.4 4.5 1.6]\n",
            " [6.7 3.1 4.7 1.5]\n",
            " [6.3 2.3 4.4 1.3]\n",
            " [5.6 3.  4.1 1.3]\n",
            " [5.5 2.5 4.  1.3]\n",
            " [5.5 2.6 4.4 1.2]\n",
            " [6.1 3.  4.6 1.4]\n",
            " [5.8 2.6 4.  1.2]\n",
            " [5.  2.3 3.3 1. ]\n",
            " [5.6 2.7 4.2 1.3]\n",
            " [5.7 3.  4.2 1.2]\n",
            " [5.7 2.9 4.2 1.3]\n",
            " [6.2 2.9 4.3 1.3]\n",
            " [5.1 2.5 3.  1.1]\n",
            " [5.7 2.8 4.1 1.3]\n",
            " [6.3 3.3 6.  2.5]\n",
            " [5.8 2.7 5.1 1.9]\n",
            " [7.1 3.  5.9 2.1]\n",
            " [6.3 2.9 5.6 1.8]\n",
            " [6.5 3.  5.8 2.2]\n",
            " [7.6 3.  6.6 2.1]\n",
            " [4.9 2.5 4.5 1.7]\n",
            " [7.3 2.9 6.3 1.8]\n",
            " [6.7 2.5 5.8 1.8]\n",
            " [7.2 3.6 6.1 2.5]\n",
            " [6.5 3.2 5.1 2. ]\n",
            " [6.4 2.7 5.3 1.9]\n",
            " [6.8 3.  5.5 2.1]\n",
            " [5.7 2.5 5.  2. ]\n",
            " [5.8 2.8 5.1 2.4]\n",
            " [6.4 3.2 5.3 2.3]\n",
            " [6.5 3.  5.5 1.8]\n",
            " [7.7 3.8 6.7 2.2]\n",
            " [7.7 2.6 6.9 2.3]\n",
            " [6.  2.2 5.  1.5]\n",
            " [6.9 3.2 5.7 2.3]\n",
            " [5.6 2.8 4.9 2. ]\n",
            " [7.7 2.8 6.7 2. ]\n",
            " [6.3 2.7 4.9 1.8]\n",
            " [6.7 3.3 5.7 2.1]\n",
            " [7.2 3.2 6.  1.8]\n",
            " [6.2 2.8 4.8 1.8]\n",
            " [6.1 3.  4.9 1.8]\n",
            " [6.4 2.8 5.6 2.1]\n",
            " [7.2 3.  5.8 1.6]\n",
            " [7.4 2.8 6.1 1.9]\n",
            " [7.9 3.8 6.4 2. ]\n",
            " [6.4 2.8 5.6 2.2]\n",
            " [6.3 2.8 5.1 1.5]\n",
            " [6.1 2.6 5.6 1.4]\n",
            " [7.7 3.  6.1 2.3]\n",
            " [6.3 3.4 5.6 2.4]\n",
            " [6.4 3.1 5.5 1.8]\n",
            " [6.  3.  4.8 1.8]\n",
            " [6.9 3.1 5.4 2.1]\n",
            " [6.7 3.1 5.6 2.4]\n",
            " [6.9 3.1 5.1 2.3]\n",
            " [5.8 2.7 5.1 1.9]\n",
            " [6.8 3.2 5.9 2.3]\n",
            " [6.7 3.3 5.7 2.5]\n",
            " [6.7 3.  5.2 2.3]\n",
            " [6.3 2.5 5.  1.9]\n",
            " [6.5 3.  5.2 2. ]\n",
            " [6.2 3.4 5.4 2.3]\n",
            " [5.9 3.  5.1 1.8]]\n",
            "line 1\n",
            "[4.90784314 3.35098039 1.43529412 0.23921569]\n",
            "hehe  False\n",
            "line 2\n",
            "[(array([[5.1, 3.5, 1.4, 0.2],\n",
            "       [4.9, 3. , 1.4, 0.2],\n",
            "       [4.7, 3.2, 1.3, 0.2],\n",
            "       [4.6, 3.1, 1.5, 0.2],\n",
            "       [5. , 3.6, 1.4, 0.2],\n",
            "       [5.4, 3.9, 1.7, 0.4],\n",
            "       [4.6, 3.4, 1.4, 0.3],\n",
            "       [5. , 3.4, 1.5, 0.2],\n",
            "       [4.4, 2.9, 1.4, 0.2],\n",
            "       [4.9, 3.1, 1.5, 0.1],\n",
            "       [5.4, 3.7, 1.5, 0.2],\n",
            "       [4.8, 3.4, 1.6, 0.2],\n",
            "       [4.8, 3. , 1.4, 0.1],\n",
            "       [4.3, 3. , 1.1, 0.1],\n",
            "       [5.8, 4. , 1.2, 0.2],\n",
            "       [5.7, 4.4, 1.5, 0.4],\n",
            "       [5.4, 3.9, 1.3, 0.4],\n",
            "       [5.1, 3.5, 1.4, 0.3],\n",
            "       [5.7, 3.8, 1.7, 0.3],\n",
            "       [5.1, 3.8, 1.5, 0.3],\n",
            "       [5.4, 3.4, 1.7, 0.2],\n",
            "       [5.1, 3.7, 1.5, 0.4],\n",
            "       [4.6, 3.6, 1. , 0.2],\n",
            "       [5.1, 3.3, 1.7, 0.5],\n",
            "       [4.8, 3.4, 1.9, 0.2],\n",
            "       [5. , 3. , 1.6, 0.2],\n",
            "       [5. , 3.4, 1.6, 0.4],\n",
            "       [5.2, 3.5, 1.5, 0.2],\n",
            "       [5.2, 3.4, 1.4, 0.2],\n",
            "       [4.7, 3.2, 1.6, 0.2],\n",
            "       [4.8, 3.1, 1.6, 0.2],\n",
            "       [5.4, 3.4, 1.5, 0.4],\n",
            "       [5.2, 4.1, 1.5, 0.1],\n",
            "       [5.5, 4.2, 1.4, 0.2],\n",
            "       [4.9, 3.1, 1.5, 0.1],\n",
            "       [5. , 3.2, 1.2, 0.2],\n",
            "       [5.5, 3.5, 1.3, 0.2],\n",
            "       [4.9, 3.1, 1.5, 0.1],\n",
            "       [4.4, 3. , 1.3, 0.2],\n",
            "       [5.1, 3.4, 1.5, 0.2],\n",
            "       [5. , 3.5, 1.3, 0.3],\n",
            "       [4.5, 2.3, 1.3, 0.3],\n",
            "       [4.4, 3.2, 1.3, 0.2],\n",
            "       [5. , 3.5, 1.6, 0.6],\n",
            "       [5.1, 3.8, 1.9, 0.4],\n",
            "       [4.8, 3. , 1.4, 0.3],\n",
            "       [5.1, 3.8, 1.6, 0.2],\n",
            "       [4.6, 3.2, 1.4, 0.2],\n",
            "       [5.3, 3.7, 1.5, 0.2],\n",
            "       [5. , 3.3, 1.4, 0.2],\n",
            "       [7. , 3.2, 4.7, 1.4],\n",
            "       [6.4, 3.2, 4.5, 1.5],\n",
            "       [6.9, 3.1, 4.9, 1.5],\n",
            "       [5.5, 2.3, 4. , 1.3],\n",
            "       [6.5, 2.8, 4.6, 1.5],\n",
            "       [5.7, 2.8, 4.5, 1.3],\n",
            "       [6.3, 3.3, 4.7, 1.6],\n",
            "       [4.9, 2.4, 3.3, 1. ],\n",
            "       [6.6, 2.9, 4.6, 1.3],\n",
            "       [5.2, 2.7, 3.9, 1.4],\n",
            "       [5. , 2. , 3.5, 1. ],\n",
            "       [5.9, 3. , 4.2, 1.5],\n",
            "       [6. , 2.2, 4. , 1. ],\n",
            "       [6.1, 2.9, 4.7, 1.4],\n",
            "       [5.6, 2.9, 3.6, 1.3],\n",
            "       [6.7, 3.1, 4.4, 1.4],\n",
            "       [5.6, 3. , 4.5, 1.5],\n",
            "       [5.8, 2.7, 4.1, 1. ],\n",
            "       [6.2, 2.2, 4.5, 1.5],\n",
            "       [5.6, 2.5, 3.9, 1.1],\n",
            "       [5.9, 3.2, 4.8, 1.8],\n",
            "       [6.1, 2.8, 4. , 1.3],\n",
            "       [6.3, 2.5, 4.9, 1.5],\n",
            "       [6.1, 2.8, 4.7, 1.2],\n",
            "       [6.4, 2.9, 4.3, 1.3],\n",
            "       [6.6, 3. , 4.4, 1.4],\n",
            "       [6.8, 2.8, 4.8, 1.4],\n",
            "       [6.7, 3. , 5. , 1.7],\n",
            "       [6. , 2.9, 4.5, 1.5],\n",
            "       [5.7, 2.6, 3.5, 1. ],\n",
            "       [5.5, 2.4, 3.8, 1.1],\n",
            "       [5.5, 2.4, 3.7, 1. ],\n",
            "       [5.8, 2.7, 3.9, 1.2],\n",
            "       [6. , 2.7, 5.1, 1.6],\n",
            "       [5.4, 3. , 4.5, 1.5],\n",
            "       [6. , 3.4, 4.5, 1.6],\n",
            "       [6.7, 3.1, 4.7, 1.5],\n",
            "       [6.3, 2.3, 4.4, 1.3],\n",
            "       [5.6, 3. , 4.1, 1.3],\n",
            "       [5.5, 2.5, 4. , 1.3],\n",
            "       [5.5, 2.6, 4.4, 1.2],\n",
            "       [6.1, 3. , 4.6, 1.4],\n",
            "       [5.8, 2.6, 4. , 1.2],\n",
            "       [5. , 2.3, 3.3, 1. ],\n",
            "       [5.6, 2.7, 4.2, 1.3],\n",
            "       [5.7, 3. , 4.2, 1.2],\n",
            "       [5.7, 2.9, 4.2, 1.3],\n",
            "       [6.2, 2.9, 4.3, 1.3],\n",
            "       [5.1, 2.5, 3. , 1.1],\n",
            "       [5.7, 2.8, 4.1, 1.3],\n",
            "       [6.3, 3.3, 6. , 2.5],\n",
            "       [5.8, 2.7, 5.1, 1.9],\n",
            "       [7.1, 3. , 5.9, 2.1],\n",
            "       [6.3, 2.9, 5.6, 1.8],\n",
            "       [6.5, 3. , 5.8, 2.2],\n",
            "       [7.6, 3. , 6.6, 2.1],\n",
            "       [4.9, 2.5, 4.5, 1.7],\n",
            "       [7.3, 2.9, 6.3, 1.8],\n",
            "       [6.7, 2.5, 5.8, 1.8],\n",
            "       [7.2, 3.6, 6.1, 2.5],\n",
            "       [6.5, 3.2, 5.1, 2. ],\n",
            "       [6.4, 2.7, 5.3, 1.9],\n",
            "       [6.8, 3. , 5.5, 2.1],\n",
            "       [5.7, 2.5, 5. , 2. ],\n",
            "       [5.8, 2.8, 5.1, 2.4],\n",
            "       [6.4, 3.2, 5.3, 2.3],\n",
            "       [6.5, 3. , 5.5, 1.8],\n",
            "       [7.7, 3.8, 6.7, 2.2],\n",
            "       [7.7, 2.6, 6.9, 2.3],\n",
            "       [6. , 2.2, 5. , 1.5],\n",
            "       [6.9, 3.2, 5.7, 2.3],\n",
            "       [5.6, 2.8, 4.9, 2. ],\n",
            "       [7.7, 2.8, 6.7, 2. ],\n",
            "       [6.3, 2.7, 4.9, 1.8],\n",
            "       [6.7, 3.3, 5.7, 2.1],\n",
            "       [7.2, 3.2, 6. , 1.8],\n",
            "       [6.2, 2.8, 4.8, 1.8],\n",
            "       [6.1, 3. , 4.9, 1.8],\n",
            "       [6.4, 2.8, 5.6, 2.1],\n",
            "       [7.2, 3. , 5.8, 1.6],\n",
            "       [7.4, 2.8, 6.1, 1.9],\n",
            "       [7.9, 3.8, 6.4, 2. ],\n",
            "       [6.4, 2.8, 5.6, 2.2],\n",
            "       [6.3, 2.8, 5.1, 1.5],\n",
            "       [6.1, 2.6, 5.6, 1.4],\n",
            "       [7.7, 3. , 6.1, 2.3],\n",
            "       [6.3, 3.4, 5.6, 2.4],\n",
            "       [6.4, 3.1, 5.5, 1.8],\n",
            "       [6. , 3. , 4.8, 1.8],\n",
            "       [6.9, 3.1, 5.4, 2.1],\n",
            "       [6.7, 3.1, 5.6, 2.4],\n",
            "       [6.9, 3.1, 5.1, 2.3],\n",
            "       [5.8, 2.7, 5.1, 1.9],\n",
            "       [6.8, 3.2, 5.9, 2.3],\n",
            "       [6.7, 3.3, 5.7, 2.5],\n",
            "       [6.7, 3. , 5.2, 2.3],\n",
            "       [6.3, 2.5, 5. , 1.9],\n",
            "       [6.5, 3. , 5.2, 2. ],\n",
            "       [6.2, 3.4, 5.4, 2.3],\n",
            "       [5.9, 3. , 5.1, 1.8]]), array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=int64))]\n",
            "[(array([[5.1, 3.5, 1.4, 0.2],\n",
            "       [4.9, 3. , 1.4, 0.2],\n",
            "       [4.7, 3.2, 1.3, 0.2],\n",
            "       [4.6, 3.1, 1.5, 0.2],\n",
            "       [5. , 3.6, 1.4, 0.2],\n",
            "       [5.4, 3.9, 1.7, 0.4],\n",
            "       [4.6, 3.4, 1.4, 0.3],\n",
            "       [5. , 3.4, 1.5, 0.2],\n",
            "       [4.4, 2.9, 1.4, 0.2],\n",
            "       [4.9, 3.1, 1.5, 0.1],\n",
            "       [5.4, 3.7, 1.5, 0.2],\n",
            "       [4.8, 3.4, 1.6, 0.2],\n",
            "       [4.8, 3. , 1.4, 0.1],\n",
            "       [4.3, 3. , 1.1, 0.1],\n",
            "       [5.8, 4. , 1.2, 0.2],\n",
            "       [5.7, 4.4, 1.5, 0.4],\n",
            "       [5.4, 3.9, 1.3, 0.4],\n",
            "       [5.1, 3.5, 1.4, 0.3],\n",
            "       [5.7, 3.8, 1.7, 0.3],\n",
            "       [5.1, 3.8, 1.5, 0.3],\n",
            "       [5.4, 3.4, 1.7, 0.2],\n",
            "       [5.1, 3.7, 1.5, 0.4],\n",
            "       [4.6, 3.6, 1. , 0.2],\n",
            "       [5.1, 3.3, 1.7, 0.5],\n",
            "       [4.8, 3.4, 1.9, 0.2],\n",
            "       [5. , 3. , 1.6, 0.2],\n",
            "       [5. , 3.4, 1.6, 0.4],\n",
            "       [5.2, 3.5, 1.5, 0.2],\n",
            "       [5.2, 3.4, 1.4, 0.2],\n",
            "       [4.7, 3.2, 1.6, 0.2],\n",
            "       [4.8, 3.1, 1.6, 0.2],\n",
            "       [5.4, 3.4, 1.5, 0.4],\n",
            "       [5.2, 4.1, 1.5, 0.1],\n",
            "       [5.5, 4.2, 1.4, 0.2],\n",
            "       [4.9, 3.1, 1.5, 0.1],\n",
            "       [5. , 3.2, 1.2, 0.2],\n",
            "       [5.5, 3.5, 1.3, 0.2],\n",
            "       [4.9, 3.1, 1.5, 0.1],\n",
            "       [4.4, 3. , 1.3, 0.2],\n",
            "       [5.1, 3.4, 1.5, 0.2],\n",
            "       [5. , 3.5, 1.3, 0.3],\n",
            "       [4.5, 2.3, 1.3, 0.3],\n",
            "       [4.4, 3.2, 1.3, 0.2],\n",
            "       [5. , 3.5, 1.6, 0.6],\n",
            "       [5.1, 3.8, 1.9, 0.4],\n",
            "       [4.8, 3. , 1.4, 0.3],\n",
            "       [5.1, 3.8, 1.6, 0.2],\n",
            "       [4.6, 3.2, 1.4, 0.2],\n",
            "       [5.3, 3.7, 1.5, 0.2],\n",
            "       [5. , 3.3, 1.4, 0.2],\n",
            "       [7. , 3.2, 4.7, 1.4],\n",
            "       [6.4, 3.2, 4.5, 1.5],\n",
            "       [6.9, 3.1, 4.9, 1.5],\n",
            "       [5.5, 2.3, 4. , 1.3],\n",
            "       [6.5, 2.8, 4.6, 1.5],\n",
            "       [5.7, 2.8, 4.5, 1.3],\n",
            "       [6.3, 3.3, 4.7, 1.6],\n",
            "       [4.9, 2.4, 3.3, 1. ],\n",
            "       [6.6, 2.9, 4.6, 1.3],\n",
            "       [5.2, 2.7, 3.9, 1.4],\n",
            "       [5. , 2. , 3.5, 1. ],\n",
            "       [5.9, 3. , 4.2, 1.5],\n",
            "       [6. , 2.2, 4. , 1. ],\n",
            "       [6.1, 2.9, 4.7, 1.4],\n",
            "       [5.6, 2.9, 3.6, 1.3],\n",
            "       [6.7, 3.1, 4.4, 1.4],\n",
            "       [5.6, 3. , 4.5, 1.5],\n",
            "       [5.8, 2.7, 4.1, 1. ],\n",
            "       [6.2, 2.2, 4.5, 1.5],\n",
            "       [5.6, 2.5, 3.9, 1.1],\n",
            "       [5.9, 3.2, 4.8, 1.8],\n",
            "       [6.1, 2.8, 4. , 1.3],\n",
            "       [6.3, 2.5, 4.9, 1.5],\n",
            "       [6.1, 2.8, 4.7, 1.2],\n",
            "       [6.4, 2.9, 4.3, 1.3],\n",
            "       [6.6, 3. , 4.4, 1.4],\n",
            "       [6.8, 2.8, 4.8, 1.4],\n",
            "       [6.7, 3. , 5. , 1.7],\n",
            "       [6. , 2.9, 4.5, 1.5],\n",
            "       [5.7, 2.6, 3.5, 1. ],\n",
            "       [5.5, 2.4, 3.8, 1.1],\n",
            "       [5.5, 2.4, 3.7, 1. ],\n",
            "       [5.8, 2.7, 3.9, 1.2],\n",
            "       [6. , 2.7, 5.1, 1.6],\n",
            "       [5.4, 3. , 4.5, 1.5],\n",
            "       [6. , 3.4, 4.5, 1.6],\n",
            "       [6.7, 3.1, 4.7, 1.5],\n",
            "       [6.3, 2.3, 4.4, 1.3],\n",
            "       [5.6, 3. , 4.1, 1.3],\n",
            "       [5.5, 2.5, 4. , 1.3],\n",
            "       [5.5, 2.6, 4.4, 1.2],\n",
            "       [6.1, 3. , 4.6, 1.4],\n",
            "       [5.8, 2.6, 4. , 1.2],\n",
            "       [5. , 2.3, 3.3, 1. ],\n",
            "       [5.6, 2.7, 4.2, 1.3],\n",
            "       [5.7, 3. , 4.2, 1.2],\n",
            "       [5.7, 2.9, 4.2, 1.3],\n",
            "       [6.2, 2.9, 4.3, 1.3],\n",
            "       [5.1, 2.5, 3. , 1.1],\n",
            "       [5.7, 2.8, 4.1, 1.3],\n",
            "       [6.3, 3.3, 6. , 2.5],\n",
            "       [5.8, 2.7, 5.1, 1.9],\n",
            "       [7.1, 3. , 5.9, 2.1],\n",
            "       [6.3, 2.9, 5.6, 1.8],\n",
            "       [6.5, 3. , 5.8, 2.2],\n",
            "       [7.6, 3. , 6.6, 2.1],\n",
            "       [4.9, 2.5, 4.5, 1.7],\n",
            "       [7.3, 2.9, 6.3, 1.8],\n",
            "       [6.7, 2.5, 5.8, 1.8],\n",
            "       [7.2, 3.6, 6.1, 2.5],\n",
            "       [6.5, 3.2, 5.1, 2. ],\n",
            "       [6.4, 2.7, 5.3, 1.9],\n",
            "       [6.8, 3. , 5.5, 2.1],\n",
            "       [5.7, 2.5, 5. , 2. ],\n",
            "       [5.8, 2.8, 5.1, 2.4],\n",
            "       [6.4, 3.2, 5.3, 2.3],\n",
            "       [6.5, 3. , 5.5, 1.8],\n",
            "       [7.7, 3.8, 6.7, 2.2],\n",
            "       [7.7, 2.6, 6.9, 2.3],\n",
            "       [6. , 2.2, 5. , 1.5],\n",
            "       [6.9, 3.2, 5.7, 2.3],\n",
            "       [5.6, 2.8, 4.9, 2. ],\n",
            "       [7.7, 2.8, 6.7, 2. ],\n",
            "       [6.3, 2.7, 4.9, 1.8],\n",
            "       [6.7, 3.3, 5.7, 2.1],\n",
            "       [7.2, 3.2, 6. , 1.8],\n",
            "       [6.2, 2.8, 4.8, 1.8],\n",
            "       [6.1, 3. , 4.9, 1.8],\n",
            "       [6.4, 2.8, 5.6, 2.1],\n",
            "       [7.2, 3. , 5.8, 1.6],\n",
            "       [7.4, 2.8, 6.1, 1.9],\n",
            "       [7.9, 3.8, 6.4, 2. ],\n",
            "       [6.4, 2.8, 5.6, 2.2],\n",
            "       [6.3, 2.8, 5.1, 1.5],\n",
            "       [6.1, 2.6, 5.6, 1.4],\n",
            "       [7.7, 3. , 6.1, 2.3],\n",
            "       [6.3, 3.4, 5.6, 2.4],\n",
            "       [6.4, 3.1, 5.5, 1.8],\n",
            "       [6. , 3. , 4.8, 1.8],\n",
            "       [6.9, 3.1, 5.4, 2.1],\n",
            "       [6.7, 3.1, 5.6, 2.4],\n",
            "       [6.9, 3.1, 5.1, 2.3],\n",
            "       [5.8, 2.7, 5.1, 1.9],\n",
            "       [6.8, 3.2, 5.9, 2.3],\n",
            "       [6.7, 3.3, 5.7, 2.5],\n",
            "       [6.7, 3. , 5.2, 2.3],\n",
            "       [6.3, 2.5, 5. , 1.9],\n",
            "       [6.5, 3. , 5.2, 2. ],\n",
            "       [6.2, 3.4, 5.4, 2.3],\n",
            "       [5.9, 3. , 5.1, 1.8]]), array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=int64)), (array([[6.4, 3.2, 4.5, 1.5],\n",
            "       [6.9, 3.1, 4.9, 1.5],\n",
            "       [5.5, 2.3, 4. , 1.3],\n",
            "       [6.5, 2.8, 4.6, 1.5],\n",
            "       [5.7, 2.8, 4.5, 1.3],\n",
            "       [6.3, 3.3, 4.7, 1.6],\n",
            "       [4.9, 2.4, 3.3, 1. ],\n",
            "       [6.6, 2.9, 4.6, 1.3],\n",
            "       [5.2, 2.7, 3.9, 1.4],\n",
            "       [5. , 2. , 3.5, 1. ],\n",
            "       [5.9, 3. , 4.2, 1.5],\n",
            "       [6. , 2.2, 4. , 1. ],\n",
            "       [6.1, 2.9, 4.7, 1.4],\n",
            "       [5.6, 2.9, 3.6, 1.3],\n",
            "       [6.7, 3.1, 4.4, 1.4],\n",
            "       [5.6, 3. , 4.5, 1.5],\n",
            "       [5.8, 2.7, 4.1, 1. ],\n",
            "       [6.2, 2.2, 4.5, 1.5],\n",
            "       [5.6, 2.5, 3.9, 1.1],\n",
            "       [5.9, 3.2, 4.8, 1.8],\n",
            "       [6.1, 2.8, 4. , 1.3],\n",
            "       [6.3, 2.5, 4.9, 1.5],\n",
            "       [6.1, 2.8, 4.7, 1.2],\n",
            "       [6.4, 2.9, 4.3, 1.3],\n",
            "       [6.6, 3. , 4.4, 1.4],\n",
            "       [6.8, 2.8, 4.8, 1.4],\n",
            "       [6.7, 3. , 5. , 1.7],\n",
            "       [6. , 2.9, 4.5, 1.5],\n",
            "       [5.7, 2.6, 3.5, 1. ],\n",
            "       [5.5, 2.4, 3.8, 1.1],\n",
            "       [5.5, 2.4, 3.7, 1. ],\n",
            "       [5.8, 2.7, 3.9, 1.2],\n",
            "       [6. , 2.7, 5.1, 1.6],\n",
            "       [5.4, 3. , 4.5, 1.5],\n",
            "       [6. , 3.4, 4.5, 1.6],\n",
            "       [6.7, 3.1, 4.7, 1.5],\n",
            "       [6.3, 2.3, 4.4, 1.3],\n",
            "       [5.6, 3. , 4.1, 1.3],\n",
            "       [5.5, 2.5, 4. , 1.3],\n",
            "       [5.5, 2.6, 4.4, 1.2],\n",
            "       [6.1, 3. , 4.6, 1.4],\n",
            "       [5.8, 2.6, 4. , 1.2],\n",
            "       [5. , 2.3, 3.3, 1. ],\n",
            "       [5.6, 2.7, 4.2, 1.3],\n",
            "       [5.7, 3. , 4.2, 1.2],\n",
            "       [5.7, 2.9, 4.2, 1.3],\n",
            "       [6.2, 2.9, 4.3, 1.3],\n",
            "       [5.1, 2.5, 3. , 1.1],\n",
            "       [5.7, 2.8, 4.1, 1.3],\n",
            "       [6.3, 3.3, 6. , 2.5],\n",
            "       [5.8, 2.7, 5.1, 1.9],\n",
            "       [7.1, 3. , 5.9, 2.1],\n",
            "       [6.3, 2.9, 5.6, 1.8],\n",
            "       [6.5, 3. , 5.8, 2.2],\n",
            "       [7.6, 3. , 6.6, 2.1],\n",
            "       [4.9, 2.5, 4.5, 1.7],\n",
            "       [7.3, 2.9, 6.3, 1.8],\n",
            "       [6.7, 2.5, 5.8, 1.8],\n",
            "       [7.2, 3.6, 6.1, 2.5],\n",
            "       [6.5, 3.2, 5.1, 2. ],\n",
            "       [6.4, 2.7, 5.3, 1.9],\n",
            "       [6.8, 3. , 5.5, 2.1],\n",
            "       [5.7, 2.5, 5. , 2. ],\n",
            "       [5.8, 2.8, 5.1, 2.4],\n",
            "       [6.4, 3.2, 5.3, 2.3],\n",
            "       [6.5, 3. , 5.5, 1.8],\n",
            "       [7.7, 3.8, 6.7, 2.2],\n",
            "       [7.7, 2.6, 6.9, 2.3],\n",
            "       [6. , 2.2, 5. , 1.5],\n",
            "       [6.9, 3.2, 5.7, 2.3],\n",
            "       [5.6, 2.8, 4.9, 2. ],\n",
            "       [7.7, 2.8, 6.7, 2. ],\n",
            "       [6.3, 2.7, 4.9, 1.8],\n",
            "       [6.7, 3.3, 5.7, 2.1],\n",
            "       [7.2, 3.2, 6. , 1.8],\n",
            "       [6.2, 2.8, 4.8, 1.8],\n",
            "       [6.1, 3. , 4.9, 1.8],\n",
            "       [6.4, 2.8, 5.6, 2.1],\n",
            "       [7.2, 3. , 5.8, 1.6],\n",
            "       [7.4, 2.8, 6.1, 1.9],\n",
            "       [7.9, 3.8, 6.4, 2. ],\n",
            "       [6.4, 2.8, 5.6, 2.2],\n",
            "       [6.3, 2.8, 5.1, 1.5],\n",
            "       [6.1, 2.6, 5.6, 1.4],\n",
            "       [7.7, 3. , 6.1, 2.3],\n",
            "       [6.3, 3.4, 5.6, 2.4],\n",
            "       [6.4, 3.1, 5.5, 1.8],\n",
            "       [6. , 3. , 4.8, 1.8],\n",
            "       [6.9, 3.1, 5.4, 2.1],\n",
            "       [6.7, 3.1, 5.6, 2.4],\n",
            "       [6.9, 3.1, 5.1, 2.3],\n",
            "       [5.8, 2.7, 5.1, 1.9],\n",
            "       [6.8, 3.2, 5.9, 2.3],\n",
            "       [6.7, 3.3, 5.7, 2.5],\n",
            "       [6.7, 3. , 5.2, 2.3],\n",
            "       [6.3, 2.5, 5. , 1.9],\n",
            "       [6.5, 3. , 5.2, 2. ],\n",
            "       [6.2, 3.4, 5.4, 2.3],\n",
            "       [5.9, 3. , 5.1, 1.8]]), array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=int64))]\n",
            "minority_class_label 1\n",
            "resampled [(array([[5.1, 3.5, 1.4, 0.2],\n",
            "       [4.9, 3. , 1.4, 0.2],\n",
            "       [4.7, 3.2, 1.3, 0.2],\n",
            "       [4.6, 3.1, 1.5, 0.2],\n",
            "       [5. , 3.6, 1.4, 0.2],\n",
            "       [5.4, 3.9, 1.7, 0.4],\n",
            "       [4.6, 3.4, 1.4, 0.3],\n",
            "       [5. , 3.4, 1.5, 0.2],\n",
            "       [4.4, 2.9, 1.4, 0.2],\n",
            "       [4.9, 3.1, 1.5, 0.1],\n",
            "       [5.4, 3.7, 1.5, 0.2],\n",
            "       [4.8, 3.4, 1.6, 0.2],\n",
            "       [4.8, 3. , 1.4, 0.1],\n",
            "       [4.3, 3. , 1.1, 0.1],\n",
            "       [5.8, 4. , 1.2, 0.2],\n",
            "       [5.7, 4.4, 1.5, 0.4],\n",
            "       [5.4, 3.9, 1.3, 0.4],\n",
            "       [5.1, 3.5, 1.4, 0.3],\n",
            "       [5.7, 3.8, 1.7, 0.3],\n",
            "       [5.1, 3.8, 1.5, 0.3],\n",
            "       [5.4, 3.4, 1.7, 0.2],\n",
            "       [5.1, 3.7, 1.5, 0.4],\n",
            "       [4.6, 3.6, 1. , 0.2],\n",
            "       [5.1, 3.3, 1.7, 0.5],\n",
            "       [4.8, 3.4, 1.9, 0.2],\n",
            "       [5. , 3. , 1.6, 0.2],\n",
            "       [5. , 3.4, 1.6, 0.4],\n",
            "       [5.2, 3.5, 1.5, 0.2],\n",
            "       [5.2, 3.4, 1.4, 0.2],\n",
            "       [4.7, 3.2, 1.6, 0.2],\n",
            "       [4.8, 3.1, 1.6, 0.2],\n",
            "       [5.4, 3.4, 1.5, 0.4],\n",
            "       [5.2, 4.1, 1.5, 0.1],\n",
            "       [5.5, 4.2, 1.4, 0.2],\n",
            "       [4.9, 3.1, 1.5, 0.1],\n",
            "       [5. , 3.2, 1.2, 0.2],\n",
            "       [5.5, 3.5, 1.3, 0.2],\n",
            "       [4.9, 3.1, 1.5, 0.1],\n",
            "       [4.4, 3. , 1.3, 0.2],\n",
            "       [5.1, 3.4, 1.5, 0.2],\n",
            "       [5. , 3.5, 1.3, 0.3],\n",
            "       [4.5, 2.3, 1.3, 0.3],\n",
            "       [4.4, 3.2, 1.3, 0.2],\n",
            "       [5. , 3.5, 1.6, 0.6],\n",
            "       [5.1, 3.8, 1.9, 0.4],\n",
            "       [4.8, 3. , 1.4, 0.3],\n",
            "       [5.1, 3.8, 1.6, 0.2],\n",
            "       [4.6, 3.2, 1.4, 0.2],\n",
            "       [5.3, 3.7, 1.5, 0.2],\n",
            "       [5. , 3.3, 1.4, 0.2],\n",
            "       [7. , 3.2, 4.7, 1.4],\n",
            "       [6.4, 3.2, 4.5, 1.5],\n",
            "       [6.9, 3.1, 4.9, 1.5],\n",
            "       [5.5, 2.3, 4. , 1.3],\n",
            "       [6.5, 2.8, 4.6, 1.5],\n",
            "       [5.7, 2.8, 4.5, 1.3],\n",
            "       [6.3, 3.3, 4.7, 1.6],\n",
            "       [4.9, 2.4, 3.3, 1. ],\n",
            "       [6.6, 2.9, 4.6, 1.3],\n",
            "       [5.2, 2.7, 3.9, 1.4],\n",
            "       [5. , 2. , 3.5, 1. ],\n",
            "       [5.9, 3. , 4.2, 1.5],\n",
            "       [6. , 2.2, 4. , 1. ],\n",
            "       [6.1, 2.9, 4.7, 1.4],\n",
            "       [5.6, 2.9, 3.6, 1.3],\n",
            "       [6.7, 3.1, 4.4, 1.4],\n",
            "       [5.6, 3. , 4.5, 1.5],\n",
            "       [5.8, 2.7, 4.1, 1. ],\n",
            "       [6.2, 2.2, 4.5, 1.5],\n",
            "       [5.6, 2.5, 3.9, 1.1],\n",
            "       [5.9, 3.2, 4.8, 1.8],\n",
            "       [6.1, 2.8, 4. , 1.3],\n",
            "       [6.3, 2.5, 4.9, 1.5],\n",
            "       [6.1, 2.8, 4.7, 1.2],\n",
            "       [6.4, 2.9, 4.3, 1.3],\n",
            "       [6.6, 3. , 4.4, 1.4],\n",
            "       [6.8, 2.8, 4.8, 1.4],\n",
            "       [6.7, 3. , 5. , 1.7],\n",
            "       [6. , 2.9, 4.5, 1.5],\n",
            "       [5.7, 2.6, 3.5, 1. ],\n",
            "       [5.5, 2.4, 3.8, 1.1],\n",
            "       [5.5, 2.4, 3.7, 1. ],\n",
            "       [5.8, 2.7, 3.9, 1.2],\n",
            "       [6. , 2.7, 5.1, 1.6],\n",
            "       [5.4, 3. , 4.5, 1.5],\n",
            "       [6. , 3.4, 4.5, 1.6],\n",
            "       [6.7, 3.1, 4.7, 1.5],\n",
            "       [6.3, 2.3, 4.4, 1.3],\n",
            "       [5.6, 3. , 4.1, 1.3],\n",
            "       [5.5, 2.5, 4. , 1.3],\n",
            "       [5.5, 2.6, 4.4, 1.2],\n",
            "       [6.1, 3. , 4.6, 1.4],\n",
            "       [5.8, 2.6, 4. , 1.2],\n",
            "       [5. , 2.3, 3.3, 1. ],\n",
            "       [5.6, 2.7, 4.2, 1.3],\n",
            "       [5.7, 3. , 4.2, 1.2],\n",
            "       [5.7, 2.9, 4.2, 1.3],\n",
            "       [6.2, 2.9, 4.3, 1.3],\n",
            "       [5.1, 2.5, 3. , 1.1],\n",
            "       [5.7, 2.8, 4.1, 1.3],\n",
            "       [6.3, 3.3, 6. , 2.5],\n",
            "       [5.8, 2.7, 5.1, 1.9],\n",
            "       [7.1, 3. , 5.9, 2.1],\n",
            "       [6.3, 2.9, 5.6, 1.8],\n",
            "       [6.5, 3. , 5.8, 2.2],\n",
            "       [7.6, 3. , 6.6, 2.1],\n",
            "       [4.9, 2.5, 4.5, 1.7],\n",
            "       [7.3, 2.9, 6.3, 1.8],\n",
            "       [6.7, 2.5, 5.8, 1.8],\n",
            "       [7.2, 3.6, 6.1, 2.5],\n",
            "       [6.5, 3.2, 5.1, 2. ],\n",
            "       [6.4, 2.7, 5.3, 1.9],\n",
            "       [6.8, 3. , 5.5, 2.1],\n",
            "       [5.7, 2.5, 5. , 2. ],\n",
            "       [5.8, 2.8, 5.1, 2.4],\n",
            "       [6.4, 3.2, 5.3, 2.3],\n",
            "       [6.5, 3. , 5.5, 1.8],\n",
            "       [7.7, 3.8, 6.7, 2.2],\n",
            "       [7.7, 2.6, 6.9, 2.3],\n",
            "       [6. , 2.2, 5. , 1.5],\n",
            "       [6.9, 3.2, 5.7, 2.3],\n",
            "       [5.6, 2.8, 4.9, 2. ],\n",
            "       [7.7, 2.8, 6.7, 2. ],\n",
            "       [6.3, 2.7, 4.9, 1.8],\n",
            "       [6.7, 3.3, 5.7, 2.1],\n",
            "       [7.2, 3.2, 6. , 1.8],\n",
            "       [6.2, 2.8, 4.8, 1.8],\n",
            "       [6.1, 3. , 4.9, 1.8],\n",
            "       [6.4, 2.8, 5.6, 2.1],\n",
            "       [7.2, 3. , 5.8, 1.6],\n",
            "       [7.4, 2.8, 6.1, 1.9],\n",
            "       [7.9, 3.8, 6.4, 2. ],\n",
            "       [6.4, 2.8, 5.6, 2.2],\n",
            "       [6.3, 2.8, 5.1, 1.5],\n",
            "       [6.1, 2.6, 5.6, 1.4],\n",
            "       [7.7, 3. , 6.1, 2.3],\n",
            "       [6.3, 3.4, 5.6, 2.4],\n",
            "       [6.4, 3.1, 5.5, 1.8],\n",
            "       [6. , 3. , 4.8, 1.8],\n",
            "       [6.9, 3.1, 5.4, 2.1],\n",
            "       [6.7, 3.1, 5.6, 2.4],\n",
            "       [6.9, 3.1, 5.1, 2.3],\n",
            "       [5.8, 2.7, 5.1, 1.9],\n",
            "       [6.8, 3.2, 5.9, 2.3],\n",
            "       [6.7, 3.3, 5.7, 2.5],\n",
            "       [6.7, 3. , 5.2, 2.3],\n",
            "       [6.3, 2.5, 5. , 1.9],\n",
            "       [6.5, 3. , 5.2, 2. ],\n",
            "       [6.2, 3.4, 5.4, 2.3],\n",
            "       [5.9, 3. , 5.1, 1.8]]), array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=int64)), (array([[6.4, 3.2, 4.5, 1.5],\n",
            "       [6.9, 3.1, 4.9, 1.5],\n",
            "       [5.5, 2.3, 4. , 1.3],\n",
            "       [6.5, 2.8, 4.6, 1.5],\n",
            "       [5.7, 2.8, 4.5, 1.3],\n",
            "       [6.3, 3.3, 4.7, 1.6],\n",
            "       [4.9, 2.4, 3.3, 1. ],\n",
            "       [6.6, 2.9, 4.6, 1.3],\n",
            "       [5.2, 2.7, 3.9, 1.4],\n",
            "       [5. , 2. , 3.5, 1. ],\n",
            "       [5.9, 3. , 4.2, 1.5],\n",
            "       [6. , 2.2, 4. , 1. ],\n",
            "       [6.1, 2.9, 4.7, 1.4],\n",
            "       [5.6, 2.9, 3.6, 1.3],\n",
            "       [6.7, 3.1, 4.4, 1.4],\n",
            "       [5.6, 3. , 4.5, 1.5],\n",
            "       [5.8, 2.7, 4.1, 1. ],\n",
            "       [6.2, 2.2, 4.5, 1.5],\n",
            "       [5.6, 2.5, 3.9, 1.1],\n",
            "       [5.9, 3.2, 4.8, 1.8],\n",
            "       [6.1, 2.8, 4. , 1.3],\n",
            "       [6.3, 2.5, 4.9, 1.5],\n",
            "       [6.1, 2.8, 4.7, 1.2],\n",
            "       [6.4, 2.9, 4.3, 1.3],\n",
            "       [6.6, 3. , 4.4, 1.4],\n",
            "       [6.8, 2.8, 4.8, 1.4],\n",
            "       [6.7, 3. , 5. , 1.7],\n",
            "       [6. , 2.9, 4.5, 1.5],\n",
            "       [5.7, 2.6, 3.5, 1. ],\n",
            "       [5.5, 2.4, 3.8, 1.1],\n",
            "       [5.5, 2.4, 3.7, 1. ],\n",
            "       [5.8, 2.7, 3.9, 1.2],\n",
            "       [6. , 2.7, 5.1, 1.6],\n",
            "       [5.4, 3. , 4.5, 1.5],\n",
            "       [6. , 3.4, 4.5, 1.6],\n",
            "       [6.7, 3.1, 4.7, 1.5],\n",
            "       [6.3, 2.3, 4.4, 1.3],\n",
            "       [5.6, 3. , 4.1, 1.3],\n",
            "       [5.5, 2.5, 4. , 1.3],\n",
            "       [5.5, 2.6, 4.4, 1.2],\n",
            "       [6.1, 3. , 4.6, 1.4],\n",
            "       [5.8, 2.6, 4. , 1.2],\n",
            "       [5. , 2.3, 3.3, 1. ],\n",
            "       [5.6, 2.7, 4.2, 1.3],\n",
            "       [5.7, 3. , 4.2, 1.2],\n",
            "       [5.7, 2.9, 4.2, 1.3],\n",
            "       [6.2, 2.9, 4.3, 1.3],\n",
            "       [5.1, 2.5, 3. , 1.1],\n",
            "       [5.7, 2.8, 4.1, 1.3],\n",
            "       [6.3, 3.3, 6. , 2.5],\n",
            "       [5.8, 2.7, 5.1, 1.9],\n",
            "       [7.1, 3. , 5.9, 2.1],\n",
            "       [6.3, 2.9, 5.6, 1.8],\n",
            "       [6.5, 3. , 5.8, 2.2],\n",
            "       [7.6, 3. , 6.6, 2.1],\n",
            "       [4.9, 2.5, 4.5, 1.7],\n",
            "       [7.3, 2.9, 6.3, 1.8],\n",
            "       [6.7, 2.5, 5.8, 1.8],\n",
            "       [7.2, 3.6, 6.1, 2.5],\n",
            "       [6.5, 3.2, 5.1, 2. ],\n",
            "       [6.4, 2.7, 5.3, 1.9],\n",
            "       [6.8, 3. , 5.5, 2.1],\n",
            "       [5.7, 2.5, 5. , 2. ],\n",
            "       [5.8, 2.8, 5.1, 2.4],\n",
            "       [6.4, 3.2, 5.3, 2.3],\n",
            "       [6.5, 3. , 5.5, 1.8],\n",
            "       [7.7, 3.8, 6.7, 2.2],\n",
            "       [7.7, 2.6, 6.9, 2.3],\n",
            "       [6. , 2.2, 5. , 1.5],\n",
            "       [6.9, 3.2, 5.7, 2.3],\n",
            "       [5.6, 2.8, 4.9, 2. ],\n",
            "       [7.7, 2.8, 6.7, 2. ],\n",
            "       [6.3, 2.7, 4.9, 1.8],\n",
            "       [6.7, 3.3, 5.7, 2.1],\n",
            "       [7.2, 3.2, 6. , 1.8],\n",
            "       [6.2, 2.8, 4.8, 1.8],\n",
            "       [6.1, 3. , 4.9, 1.8],\n",
            "       [6.4, 2.8, 5.6, 2.1],\n",
            "       [7.2, 3. , 5.8, 1.6],\n",
            "       [7.4, 2.8, 6.1, 1.9],\n",
            "       [7.9, 3.8, 6.4, 2. ],\n",
            "       [6.4, 2.8, 5.6, 2.2],\n",
            "       [6.3, 2.8, 5.1, 1.5],\n",
            "       [6.1, 2.6, 5.6, 1.4],\n",
            "       [7.7, 3. , 6.1, 2.3],\n",
            "       [6.3, 3.4, 5.6, 2.4],\n",
            "       [6.4, 3.1, 5.5, 1.8],\n",
            "       [6. , 3. , 4.8, 1.8],\n",
            "       [6.9, 3.1, 5.4, 2.1],\n",
            "       [6.7, 3.1, 5.6, 2.4],\n",
            "       [6.9, 3.1, 5.1, 2.3],\n",
            "       [5.8, 2.7, 5.1, 1.9],\n",
            "       [6.8, 3.2, 5.9, 2.3],\n",
            "       [6.7, 3.3, 5.7, 2.5],\n",
            "       [6.7, 3. , 5.2, 2.3],\n",
            "       [6.3, 2.5, 5. , 1.9],\n",
            "       [6.5, 3. , 5.2, 2. ],\n",
            "       [6.2, 3.4, 5.4, 2.3],\n",
            "       [5.9, 3. , 5.1, 1.8]]), array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=int64))]\n",
            "Class 0 has 50 instances after oversampling\n",
            "Class 1 has 199 instances after oversampling\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[None, None]"
            ]
          },
          "execution_count": 135,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "unique_classes, counts = np.unique(y, return_counts=True)\n",
        "print(dict(zip(unique_classes, counts)))\n",
        "\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "# Calcul des instances par classe\n",
        "class_counts = dict(zip(*np.unique(y, return_counts=True)))\n",
        "\n",
        "# Affichage du nombre d'instances par classe\n",
        "for label, count in class_counts.items():\n",
        "    print('Class {} has {} instances'.format(label, count))\n",
        "\n",
        "# Cration et utilisation de FCM_smote\n",
        "FCM_smote = FCMCENTERSMOTE(\n",
        "    kmeans_args={'n_clusters': num_clusters},\n",
        "    smote_args={'k_neighbors': 2},\n",
        "    imbalance_ratio_threshold=1,\n",
        "    density_power=4\n",
        ")\n",
        "X_resampled, y_resampled = FCM_smote.fit_resample(X, y)\n",
        "\n",
        "[print('Class {} has {} instances after oversampling'.format(label, count))\n",
        " for label, count in zip(*np.unique(y_resampled, return_counts=True))]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 136,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.1, random_state=42)\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 138,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialiser le classificateur k-NN avec k=3\n",
        "knn = KNeighborsClassifier(n_neighbors=3)\n",
        "\n",
        "# Entraner le modle\n",
        "knn.fit(X_train, y_train)\n",
        "\n",
        "# Prdire les tiquettes sur l'ensemble de test\n",
        "y_pred = knn.predict(X_test)\n",
        "\n",
        "from sklearn import svm\n",
        "clf = svm.SVC(kernel='linear')\n",
        "clf.fit(X_train, y_train)\n",
        "y_pred = clf.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 139,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "recall 1.0\n",
            "specificity_val 1.0\n",
            "Precision: 1.0\n",
            "Recall: 1.0\n",
            "G-M 1.0\n",
            "Accuracy: 1.0\n",
            "F1-score: 1.0\n",
            "AUC: 1.0\n"
          ]
        }
      ],
      "source": [
        "from sklearn import metrics\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import recall_score, accuracy_score, confusion_matrix\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "X = df.iloc[:,0:4].to_numpy()\n",
        "y=df.iloc[:,4].to_numpy()\n",
        "df['test']=y\n",
        "df['test'] = df['test'].replace('Iris-setosa', 0)\n",
        "df['test'] = df['test'].replace('Iris-virginica', 1)\n",
        "df['test'] = df['test'].replace('Iris-versicolor', 0)\n",
        "#df['test'] = df['test'].replace(' pp', 0)\n",
        "y=df['test'].to_numpy()\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.1, random_state=42)\n",
        "\n",
        "\n",
        "# Calcul de la sensibilit (recall)\n",
        "def sensitivity(y_true, y_pred):\n",
        "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
        "    return tp / (tp + fn)\n",
        "\n",
        "# Calcul de la spcificit\n",
        "def specificity(y_true, y_pred):\n",
        "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
        "    return tn / (tn + fp)\n",
        "\n",
        "# Initialiser le classificateur k-NN avec k=3\n",
        "knn = KNeighborsClassifier(n_neighbors=3)\n",
        "\n",
        "# Entraner le modle\n",
        "knn.fit(X_train, y_train)\n",
        "\n",
        "# Prdire les tiquettes sur l'ensemble de test\n",
        "y_pred = knn.predict(X_test)\n",
        "\n",
        "recall = recall_score(y_test, y_pred)\n",
        "specificity_val = specificity(y_test, y_pred)\n",
        "g_mean = (recall * specificity_val) ** 0.5\n",
        "print(\"recall\",recall)\n",
        "print(\"specificity_val\",specificity_val)\n",
        "print(\"Precision:\",metrics.precision_score(y_test, y_pred))\n",
        "print(\"Recall:\",metrics.recall_score(y_test, y_pred))\n",
        "print(\"G-M\",g_mean)\n",
        "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n",
        "print(\"F1-score:\",metrics.f1_score(y_test, y_pred))\n",
        "print(\"AUC:\",metrics.roc_auc_score(y_test, y_pred))\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
